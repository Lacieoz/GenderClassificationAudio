{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./csv/features.csv doesn't exists\n",
      "Features will be calculated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "\n",
    "n_mfcc = 39\n",
    "csv_file_save = './csv/features.csv'\n",
    "calculate_csv = None\n",
    "\n",
    "if not os.path.exists('./csv'):\n",
    "    os.makedirs('./csv')\n",
    "\n",
    "if os.path.exists(csv_file_save):\n",
    "    print (\"File \" + csv_file_save + \" exists\")\n",
    "    print (\"Features won't be recalculated\")\n",
    "    calculate_csv = False\n",
    "else:\n",
    "    print (\"File \" + csv_file_save + \" doesn't exists\")\n",
    "    print (\"Features will be calculated\")\n",
    "    calculate_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract info speakers \n",
    "\n",
    "file_speaker = \"./LibriSpeech/SPEAKERS.TXT\"\n",
    "speakers = []\n",
    "\n",
    "f = open(file_speaker, \"r\")\n",
    "for line in f:\n",
    "    if line[0] == \";\":\n",
    "        continue\n",
    "    else:\n",
    "        speakers.append( str.rstrip(line) ) # rstrip to remove \\n at the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14   | F | train-clean-360  | 25.03 | Kristin LeMoine',\n",
       " '16   | F | train-clean-360  | 25.11 | Alys AtteWater',\n",
       " '17   | M | train-clean-360  | 25.04 | Gord Mackenzie',\n",
       " '19   | F | train-clean-100  | 25.19 | Kara Shallenberg',\n",
       " '20   | F | train-other-500  | 30.07 | Gesine',\n",
       " '22   | F | train-clean-360  | 25.14 | Michelle Crandall',\n",
       " '23   | F | train-clean-360  | 25.23 | Anita Roy Dobbs',\n",
       " '25   | M | train-other-500  | 30.16 | John Gonzalez',\n",
       " '26   | M | train-clean-100  | 25.08 | Denny Sayers',\n",
       " '27   | M | train-clean-100  | 20.14 | Sean McKinley']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract speakers gender \n",
    "# store in dictionary and in list to choose train and test speakers\n",
    "\n",
    "dict_speakers = {}\n",
    "list_speakers = []\n",
    "for speaker in speakers:\n",
    "    speaker_split = speaker.split()\n",
    "    speaker_split = [word for word in speaker_split if word != \"|\"]\n",
    "    \n",
    "    # indexes = 0 : id, 1 : gender, 2 : dataset\n",
    "    if speaker_split[2] == \"dev-clean\":\n",
    "        dict_speakers[speaker_split[0]] = speaker_split[1]\n",
    "        list_speakers.append(speaker_split[0])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'84': 'F',\n",
       " '174': 'M',\n",
       " '251': 'M',\n",
       " '422': 'M',\n",
       " '652': 'M',\n",
       " '777': 'M',\n",
       " '1272': 'M',\n",
       " '1462': 'F',\n",
       " '1673': 'F',\n",
       " '1919': 'F',\n",
       " '1988': 'F',\n",
       " '1993': 'F',\n",
       " '2035': 'F',\n",
       " '2078': 'M',\n",
       " '2086': 'M',\n",
       " '2277': 'F',\n",
       " '2412': 'F',\n",
       " '2428': 'M',\n",
       " '2803': 'M',\n",
       " '2902': 'M',\n",
       " '3000': 'M',\n",
       " '3081': 'F',\n",
       " '3170': 'M',\n",
       " '3536': 'F',\n",
       " '3576': 'F',\n",
       " '3752': 'M',\n",
       " '3853': 'F',\n",
       " '5338': 'F',\n",
       " '5536': 'M',\n",
       " '5694': 'M',\n",
       " '5895': 'F',\n",
       " '6241': 'M',\n",
       " '6295': 'M',\n",
       " '6313': 'F',\n",
       " '6319': 'F',\n",
       " '6345': 'F',\n",
       " '7850': 'F',\n",
       " '7976': 'M',\n",
       " '8297': 'M',\n",
       " '8842': 'F'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get audio files info : name and path \n",
    "\n",
    "if calculate_csv:\n",
    "    audio_files = []\n",
    "\n",
    "    root = \"./\"\n",
    "    path = os.path.join(root, \"LibriSpeech\")\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for file in filenames:\n",
    "            if file[-5:] == \".flac\":\n",
    "                audio_files.append({\"dirpath\": dirpath, \"filename\": file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703\n"
     ]
    }
   ],
   "source": [
    "if calculate_csv:\n",
    "    print(len(audio_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0000.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0001.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0002.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0003.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0004.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0005.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0006.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0007.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0008.flac'}, {'dirpath': './LibriSpeech\\\\dev-clean\\\\1272\\\\128104', 'filename': '1272-128104-0009.flac'}]\n"
     ]
    }
   ],
   "source": [
    "if calculate_csv:\n",
    "    print(audio_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels genders (target) for each file \n",
    "\n",
    "if calculate_csv:\n",
    "    gender_labels = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        file = audio_file[\"filename\"]\n",
    "        index = 0\n",
    "        for char in file:\n",
    "            if char != \"-\":\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n",
    "        id_speaker = file[:index]\n",
    "        audio_file[\"id_speaker\"] = id_speaker\n",
    "\n",
    "        gender_labels.append(dict_speakers[id_speaker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703\n"
     ]
    }
   ],
   "source": [
    "if calculate_csv:\n",
    "    print(len(gender_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features file 100/2703\n",
      "Extracting features file 200/2703\n",
      "Extracting features file 300/2703\n",
      "Extracting features file 400/2703\n",
      "Extracting features file 500/2703\n",
      "Extracting features file 600/2703\n",
      "Extracting features file 700/2703\n",
      "Extracting features file 800/2703\n",
      "Extracting features file 900/2703\n",
      "Extracting features file 1000/2703\n",
      "Extracting features file 1100/2703\n",
      "Extracting features file 1200/2703\n",
      "Extracting features file 1300/2703\n",
      "Extracting features file 1400/2703\n",
      "Extracting features file 1500/2703\n",
      "Extracting features file 1600/2703\n",
      "Extracting features file 1700/2703\n",
      "Extracting features file 1800/2703\n",
      "Extracting features file 1900/2703\n",
      "Extracting features file 2000/2703\n",
      "Extracting features file 2100/2703\n",
      "Extracting features file 2200/2703\n",
      "Extracting features file 2300/2703\n",
      "Extracting features file 2400/2703\n",
      "Extracting features file 2500/2703\n",
      "Extracting features file 2600/2703\n",
      "Extracting features file 2700/2703\n",
      "End of extracting features\n"
     ]
    }
   ],
   "source": [
    "# extract mfcc features and make mean for each feature\n",
    "\n",
    "if calculate_csv:\n",
    "\n",
    "    input_features = []\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Extracting features file \" + str(counter) + \"/\" + str(len(audio_files)))\n",
    "\n",
    "        directory = audio_file[\"dirpath\"]\n",
    "        filename = audio_file[\"filename\"]\n",
    "\n",
    "        y, sr = librosa.load(directory + \"/\" + filename)\n",
    "        hop_length = 512\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "        mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "        input_features.append(mfccs_processed)\n",
    "\n",
    "    print(\"End of extracting features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2703\n"
     ]
    }
   ],
   "source": [
    "if calculate_csv:\n",
    "    print(len(input_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "if calculate_csv:\n",
    "    print(len(input_features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing row 500/2703\n",
      "Writing row 1000/2703\n",
      "Writing row 1500/2703\n",
      "Writing row 2000/2703\n",
      "Writing row 2500/2703\n",
      "End of writing csv\n"
     ]
    }
   ],
   "source": [
    "# save features on csv with additional info and labels\n",
    "\n",
    "if calculate_csv:\n",
    "\n",
    "    with open(csv_file_save, 'w', newline='') as csvfile:\n",
    "        feat_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        row_to_write = ['label', 'label_value', 'id_speaker']\n",
    "        for f in range(n_mfcc):\n",
    "            row_to_write.append('f' + str(f))\n",
    "\n",
    "        feat_writer.writerow(row_to_write)\n",
    "\n",
    "        for input_feature in input_features:\n",
    "\n",
    "            class_label = gender_labels[index]\n",
    "            if class_label == \"M\":\n",
    "                class_label = 0\n",
    "            else:\n",
    "                class_label = 1\n",
    "\n",
    "            row_to_write = [class_label, gender_labels[index], audio_files[index][\"id_speaker\"]]\n",
    "\n",
    "            index += 1\n",
    "\n",
    "            if index % 500 == 0:\n",
    "                print(\"Writing row \" + str(index) + \"/\" + str(len(audio_files)))\n",
    "            for features in input_feature:\n",
    "                row_to_write.append(features)\n",
    "\n",
    "            feat_writer.writerow(row_to_write)\n",
    "    print(\"End of writing csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1272, 1673, 3752, 7850, 3000, 8842, 2078, 84, 2277, 3081, 422, 5338, 1462, 7976, 251, 6319, 652, 3170, 6313, 2428, 6345, 777, 8297, 6295, 5536, 3853, 3576, 2412]\n",
      "[6241, 2803, 2902, 3536, 1988, 2035]\n",
      "[174, 2086, 1993, 5895, 5694, 1919]\n"
     ]
    }
   ],
   "source": [
    "# choose speakers to put in each dataset\n",
    "\n",
    "random.shuffle(list_speakers)\n",
    "\n",
    "speakers_train = []\n",
    "speakers_val   = []\n",
    "speakers_test  = []\n",
    "count_males   = 0\n",
    "count_females = 0 \n",
    "n_speakers = len(list_speakers)\n",
    "n_speakers_for_gender_train = (n_speakers / 2) * 0.7\n",
    "n_speakers_for_gender_train_val = (n_speakers / 2) * 0.85\n",
    "\n",
    "for speaker in list_speakers:\n",
    "    gender = dict_speakers[speaker]\n",
    "    if gender == 'M':\n",
    "        if count_males < n_speakers_for_gender_train: \n",
    "            speakers_train.append(int(speaker))\n",
    "        elif count_males < n_speakers_for_gender_train_val: \n",
    "            speakers_val.append(int(speaker))\n",
    "        else:\n",
    "            speakers_test.append(int(speaker))\n",
    "        count_males += 1\n",
    "    elif gender == 'F':\n",
    "        if count_females < n_speakers_for_gender_train: \n",
    "            speakers_train.append(int(speaker))\n",
    "        elif count_females < n_speakers_for_gender_train_val: \n",
    "            speakers_val.append(int(speaker))\n",
    "        else:\n",
    "            speakers_test.append(int(speaker))\n",
    "        count_females += 1\n",
    "    \n",
    "print(speakers_train)\n",
    "print(speakers_val)\n",
    "print(speakers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1915, 1)\n",
      "(1915, 39)\n",
      "(389, 1)\n",
      "(389, 39)\n",
      "(399, 1)\n",
      "(399, 39)\n",
      "(1915, 1)\n",
      "(389, 1)\n",
      "(399, 1)\n"
     ]
    }
   ],
   "source": [
    "# read csv to get inputs and targets\n",
    "\n",
    "my_data = np.genfromtxt(csv_file_save, delimiter=',', skip_header=1)\n",
    "\n",
    "labels_train = []\n",
    "data_train   = []\n",
    "labels_val   = []\n",
    "data_val     = []\n",
    "labels_test  = []\n",
    "data_test    = []\n",
    "labels_train_svm = []\n",
    "labels_val_svm = []\n",
    "labels_test_svm  = []\n",
    "\n",
    "for row in my_data:\n",
    "    if row[2] in speakers_train:\n",
    "        labels_train.append([row[0]])\n",
    "        data_train.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_train_svm.append([1])\n",
    "        else:\n",
    "            labels_train_svm.append([-1])\n",
    "    elif row[2] in speakers_val:\n",
    "        labels_val.append([row[0]])\n",
    "        data_val.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_val_svm.append([1])\n",
    "        else:\n",
    "            labels_val_svm.append([-1])\n",
    "    else:\n",
    "        labels_test.append([row[0]])\n",
    "        data_test.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_test_svm.append([1])\n",
    "        else:\n",
    "            labels_test_svm.append([-1])\n",
    "\n",
    "data_train = list(zip(labels_train, data_train, labels_train_svm))\n",
    "random.shuffle(data_train)\n",
    "labels_train, data_train, labels_train_svm = zip(*data_train)\n",
    "\n",
    "data_val = list(zip(labels_val, data_val, labels_val_svm))\n",
    "random.shuffle(data_val)\n",
    "labels_val, data_val, labels_val_svm = zip(*data_val)\n",
    "\n",
    "data_test = list(zip(labels_test, data_test, labels_test_svm))\n",
    "random.shuffle(data_test)\n",
    "labels_test, data_test, labels_test_svm = zip(*data_test)\n",
    "\n",
    "labels_train      = np.array(labels_train)\n",
    "data_train        = np.array(data_train)\n",
    "labels_val        = np.array(labels_val)\n",
    "data_val          = np.array(data_val)\n",
    "labels_test       = np.array(labels_test)\n",
    "data_test         = np.array(data_test)\n",
    "labels_train_svm  = np.array(labels_train_svm)\n",
    "labels_val_svm    = np.array(labels_val_svm)\n",
    "labels_test_svm   = np.array(labels_test_svm)\n",
    "\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(data_val.shape)\n",
    "print(labels_test.shape)\n",
    "print(data_test.shape)\n",
    "print(labels_train_svm.shape)\n",
    "print(labels_val_svm.shape)\n",
    "print(labels_test_svm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1915, 39]) torch.Size([1915, 1])\n",
      "torch.Size([389, 39]) torch.Size([389, 1])\n",
      "torch.Size([399, 39]) torch.Size([399, 1])\n"
     ]
    }
   ],
   "source": [
    "# cast data to tensor\n",
    "\n",
    "data_train_tensor   = torch.from_numpy(data_train).float()\n",
    "labels_train_tensor = torch.from_numpy(labels_train).float()\n",
    "data_val_tensor   = torch.from_numpy(data_val).float()\n",
    "labels_val_tensor = torch.from_numpy(labels_val).float()\n",
    "data_test_tensor    = torch.from_numpy(data_test).float()\n",
    "labels_test_tensor  = torch.from_numpy(labels_test).float()\n",
    "\n",
    "print(data_train_tensor.shape, labels_train_tensor.shape)\n",
    "print(data_val_tensor.shape, labels_val_tensor.shape)\n",
    "print(data_test_tensor.shape, labels_test_tensor.shape)\n",
    "\n",
    "labels_train_svm_tensor = torch.from_numpy(labels_train_svm).float()\n",
    "labels_val_svm_tensor   = torch.from_numpy(labels_val_svm).float()\n",
    "labels_test_svm_tensor  = torch.from_numpy(labels_test_svm).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Val: 0.728\n",
      "Accuracy_Test: 0.779\n"
     ]
    }
   ],
   "source": [
    "# kNN MODEL WITH RESULTS\n",
    "\n",
    "label_pred_val = []\n",
    "\n",
    "for val_data in data_val_tensor:\n",
    "    dist = torch.norm(data_train_tensor - val_data, dim=1, p=None)\n",
    "    knn  = dist.topk(3, largest=False)\n",
    "    \n",
    "    result = 0\n",
    "    for index in knn.indices:\n",
    "        result += int(labels_train_tensor[index])\n",
    "    result = (result / 3)\n",
    "    \n",
    "    label_pred_val.append([result])\n",
    "\n",
    "label_pred_val = torch.as_tensor(label_pred_val)\n",
    "\n",
    "# Accuracy test \n",
    "output_val  = (label_pred_val > 0.5).float()\n",
    "correct_val = (output_val == labels_val_tensor).float().sum()\n",
    "\n",
    "print(\"Accuracy_Val: {:.3f}\".format(correct_val/labels_val_tensor.shape[0]))\n",
    "\n",
    "label_pred_test = []\n",
    "\n",
    "for test_data in data_test_tensor:\n",
    "    dist = torch.norm(data_train_tensor - test_data, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    \n",
    "    result = 0\n",
    "    for index in knn.indices:\n",
    "        result += int(labels_train_tensor[index])\n",
    "    result = (result / 3)\n",
    "    \n",
    "    label_pred_test.append([result])\n",
    "\n",
    "label_pred_test = torch.as_tensor(label_pred_test)\n",
    "\n",
    "# Accuracy test \n",
    "output_test  = (label_pred_test > 0.5).float()\n",
    "correct_test = (output_test == labels_test_tensor).float().sum()\n",
    "\n",
    "print(\"Accuracy_Test: {:.3f}\".format(correct_test/labels_test_tensor.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000, Loss: 2087.148, Accuracy: 0.486, Loss_Val: 457.202, Accuracy_Val: 0.483\n",
      "Epoch 30/10000, Loss: 2012.589, Accuracy: 0.496, Loss_Val: 446.083, Accuracy_Val: 0.473\n",
      "Epoch 45/10000, Loss: 1897.559, Accuracy: 0.514, Loss_Val: 377.956, Accuracy_Val: 0.519\n",
      "Epoch 60/10000, Loss: 1754.988, Accuracy: 0.539, Loss_Val: 365.458, Accuracy_Val: 0.530\n",
      "Epoch 75/10000, Loss: 1732.917, Accuracy: 0.551, Loss_Val: 386.679, Accuracy_Val: 0.517\n",
      "Epoch 90/10000, Loss: 1645.777, Accuracy: 0.549, Loss_Val: 344.579, Accuracy_Val: 0.560\n",
      "Epoch 105/10000, Loss: 1578.652, Accuracy: 0.573, Loss_Val: 345.134, Accuracy_Val: 0.586\n",
      "Epoch 120/10000, Loss: 1595.119, Accuracy: 0.586, Loss_Val: 320.953, Accuracy_Val: 0.586\n",
      "Epoch 135/10000, Loss: 1628.090, Accuracy: 0.584, Loss_Val: 313.785, Accuracy_Val: 0.594\n",
      "Epoch 150/10000, Loss: 1416.328, Accuracy: 0.628, Loss_Val: 323.534, Accuracy_Val: 0.571\n",
      "Epoch 165/10000, Loss: 1496.648, Accuracy: 0.610, Loss_Val: 313.767, Accuracy_Val: 0.568\n",
      "Epoch 180/10000, Loss: 1399.208, Accuracy: 0.623, Loss_Val: 267.893, Accuracy_Val: 0.661\n",
      "Epoch 195/10000, Loss: 1339.121, Accuracy: 0.636, Loss_Val: 264.501, Accuracy_Val: 0.658\n",
      "Epoch 210/10000, Loss: 1308.263, Accuracy: 0.658, Loss_Val: 302.406, Accuracy_Val: 0.589\n",
      "Epoch 225/10000, Loss: 1296.610, Accuracy: 0.654, Loss_Val: 285.640, Accuracy_Val: 0.656\n",
      "Epoch 240/10000, Loss: 1240.236, Accuracy: 0.676, Loss_Val: 283.202, Accuracy_Val: 0.586\n",
      "Epoch 255/10000, Loss: 1212.879, Accuracy: 0.675, Loss_Val: 277.520, Accuracy_Val: 0.627\n",
      "Epoch 270/10000, Loss: 1228.188, Accuracy: 0.675, Loss_Val: 254.010, Accuracy_Val: 0.676\n",
      "Epoch 285/10000, Loss: 1169.067, Accuracy: 0.692, Loss_Val: 277.633, Accuracy_Val: 0.635\n",
      "Epoch 300/10000, Loss: 1076.065, Accuracy: 0.720, Loss_Val: 255.005, Accuracy_Val: 0.668\n",
      "Epoch 315/10000, Loss: 1122.645, Accuracy: 0.700, Loss_Val: 257.878, Accuracy_Val: 0.658\n",
      "Epoch 330/10000, Loss: 1073.573, Accuracy: 0.725, Loss_Val: 252.339, Accuracy_Val: 0.656\n",
      "Epoch 345/10000, Loss: 1041.741, Accuracy: 0.733, Loss_Val: 238.471, Accuracy_Val: 0.702\n",
      "Epoch 360/10000, Loss: 988.355, Accuracy: 0.752, Loss_Val: 246.920, Accuracy_Val: 0.653\n",
      "Epoch 375/10000, Loss: 969.172, Accuracy: 0.758, Loss_Val: 228.273, Accuracy_Val: 0.676\n",
      "Epoch 390/10000, Loss: 989.640, Accuracy: 0.744, Loss_Val: 243.724, Accuracy_Val: 0.702\n",
      "Epoch 405/10000, Loss: 998.442, Accuracy: 0.752, Loss_Val: 250.090, Accuracy_Val: 0.666\n",
      "Epoch 420/10000, Loss: 886.203, Accuracy: 0.792, Loss_Val: 214.451, Accuracy_Val: 0.704\n",
      "Epoch 435/10000, Loss: 910.435, Accuracy: 0.778, Loss_Val: 221.926, Accuracy_Val: 0.692\n",
      "Epoch 450/10000, Loss: 894.799, Accuracy: 0.787, Loss_Val: 220.311, Accuracy_Val: 0.702\n",
      "Epoch 465/10000, Loss: 873.959, Accuracy: 0.781, Loss_Val: 215.729, Accuracy_Val: 0.738\n",
      "Epoch 480/10000, Loss: 852.111, Accuracy: 0.799, Loss_Val: 215.917, Accuracy_Val: 0.704\n",
      "Epoch 495/10000, Loss: 832.544, Accuracy: 0.798, Loss_Val: 205.108, Accuracy_Val: 0.735\n",
      "Epoch 510/10000, Loss: 854.300, Accuracy: 0.787, Loss_Val: 216.086, Accuracy_Val: 0.733\n",
      "Epoch 525/10000, Loss: 806.074, Accuracy: 0.806, Loss_Val: 226.204, Accuracy_Val: 0.704\n",
      "Epoch 540/10000, Loss: 809.550, Accuracy: 0.804, Loss_Val: 213.192, Accuracy_Val: 0.728\n",
      "Epoch 555/10000, Loss: 814.384, Accuracy: 0.806, Loss_Val: 212.856, Accuracy_Val: 0.733\n",
      "Epoch 570/10000, Loss: 782.366, Accuracy: 0.806, Loss_Val: 207.553, Accuracy_Val: 0.725\n",
      "Epoch 585/10000, Loss: 751.482, Accuracy: 0.822, Loss_Val: 204.095, Accuracy_Val: 0.738\n",
      "Epoch 600/10000, Loss: 780.713, Accuracy: 0.817, Loss_Val: 223.328, Accuracy_Val: 0.722\n",
      "Epoch 615/10000, Loss: 720.120, Accuracy: 0.833, Loss_Val: 206.510, Accuracy_Val: 0.733\n",
      "Epoch 630/10000, Loss: 696.902, Accuracy: 0.839, Loss_Val: 209.679, Accuracy_Val: 0.720\n",
      "Epoch 645/10000, Loss: 693.641, Accuracy: 0.841, Loss_Val: 199.559, Accuracy_Val: 0.746\n",
      "Epoch 660/10000, Loss: 676.103, Accuracy: 0.842, Loss_Val: 200.624, Accuracy_Val: 0.740\n",
      "Epoch 675/10000, Loss: 676.010, Accuracy: 0.849, Loss_Val: 216.133, Accuracy_Val: 0.704\n",
      "Epoch 690/10000, Loss: 678.053, Accuracy: 0.838, Loss_Val: 197.851, Accuracy_Val: 0.761\n",
      "Epoch 705/10000, Loss: 674.411, Accuracy: 0.845, Loss_Val: 221.744, Accuracy_Val: 0.712\n",
      "Epoch 720/10000, Loss: 636.304, Accuracy: 0.861, Loss_Val: 213.309, Accuracy_Val: 0.738\n",
      "Epoch 735/10000, Loss: 623.876, Accuracy: 0.855, Loss_Val: 216.643, Accuracy_Val: 0.733\n",
      "Epoch 750/10000, Loss: 669.386, Accuracy: 0.839, Loss_Val: 203.064, Accuracy_Val: 0.738\n",
      "Epoch 765/10000, Loss: 658.748, Accuracy: 0.848, Loss_Val: 199.246, Accuracy_Val: 0.730\n",
      "Epoch 780/10000, Loss: 637.908, Accuracy: 0.857, Loss_Val: 207.036, Accuracy_Val: 0.753\n",
      "Epoch 795/10000, Loss: 601.525, Accuracy: 0.865, Loss_Val: 205.629, Accuracy_Val: 0.720\n",
      "Epoch 810/10000, Loss: 579.303, Accuracy: 0.874, Loss_Val: 207.935, Accuracy_Val: 0.743\n",
      "Epoch 825/10000, Loss: 624.024, Accuracy: 0.857, Loss_Val: 190.170, Accuracy_Val: 0.738\n",
      "Epoch 840/10000, Loss: 593.648, Accuracy: 0.868, Loss_Val: 188.382, Accuracy_Val: 0.758\n",
      "Epoch 855/10000, Loss: 563.812, Accuracy: 0.865, Loss_Val: 197.303, Accuracy_Val: 0.730\n",
      "Epoch 870/10000, Loss: 580.635, Accuracy: 0.868, Loss_Val: 194.256, Accuracy_Val: 0.722\n",
      "Epoch 885/10000, Loss: 548.137, Accuracy: 0.870, Loss_Val: 188.276, Accuracy_Val: 0.740\n",
      "Epoch 900/10000, Loss: 564.206, Accuracy: 0.877, Loss_Val: 198.067, Accuracy_Val: 0.735\n",
      "Epoch 915/10000, Loss: 527.842, Accuracy: 0.878, Loss_Val: 179.789, Accuracy_Val: 0.766\n",
      "Epoch 930/10000, Loss: 547.523, Accuracy: 0.873, Loss_Val: 206.229, Accuracy_Val: 0.730\n",
      "Epoch 945/10000, Loss: 530.751, Accuracy: 0.879, Loss_Val: 185.375, Accuracy_Val: 0.766\n",
      "Epoch 960/10000, Loss: 519.311, Accuracy: 0.886, Loss_Val: 198.079, Accuracy_Val: 0.753\n",
      "Epoch 975/10000, Loss: 523.891, Accuracy: 0.880, Loss_Val: 185.582, Accuracy_Val: 0.794\n",
      "Epoch 990/10000, Loss: 507.115, Accuracy: 0.885, Loss_Val: 191.919, Accuracy_Val: 0.784\n",
      "Epoch 1005/10000, Loss: 510.887, Accuracy: 0.886, Loss_Val: 201.927, Accuracy_Val: 0.743\n",
      "Epoch 1020/10000, Loss: 478.098, Accuracy: 0.896, Loss_Val: 186.926, Accuracy_Val: 0.769\n",
      "Epoch 1035/10000, Loss: 489.507, Accuracy: 0.892, Loss_Val: 176.433, Accuracy_Val: 0.779\n",
      "Epoch 1050/10000, Loss: 481.697, Accuracy: 0.895, Loss_Val: 193.404, Accuracy_Val: 0.756\n",
      "Epoch 1065/10000, Loss: 485.172, Accuracy: 0.889, Loss_Val: 187.857, Accuracy_Val: 0.784\n",
      "Epoch 1080/10000, Loss: 469.127, Accuracy: 0.892, Loss_Val: 184.352, Accuracy_Val: 0.766\n",
      "Epoch 1095/10000, Loss: 436.337, Accuracy: 0.911, Loss_Val: 181.384, Accuracy_Val: 0.787\n",
      "Epoch 1110/10000, Loss: 464.709, Accuracy: 0.898, Loss_Val: 186.595, Accuracy_Val: 0.763\n",
      "Epoch 1125/10000, Loss: 454.660, Accuracy: 0.898, Loss_Val: 178.438, Accuracy_Val: 0.761\n",
      "Epoch 1140/10000, Loss: 453.279, Accuracy: 0.906, Loss_Val: 176.530, Accuracy_Val: 0.792\n",
      "Epoch 1155/10000, Loss: 420.178, Accuracy: 0.910, Loss_Val: 203.265, Accuracy_Val: 0.735\n",
      "Epoch 1170/10000, Loss: 447.934, Accuracy: 0.900, Loss_Val: 177.062, Accuracy_Val: 0.776\n",
      "Epoch 1185/10000, Loss: 428.654, Accuracy: 0.909, Loss_Val: 181.644, Accuracy_Val: 0.771\n",
      "Epoch 1200/10000, Loss: 407.967, Accuracy: 0.914, Loss_Val: 188.885, Accuracy_Val: 0.746\n",
      "Epoch 1215/10000, Loss: 408.785, Accuracy: 0.912, Loss_Val: 167.325, Accuracy_Val: 0.797\n",
      "Epoch 1230/10000, Loss: 409.158, Accuracy: 0.910, Loss_Val: 175.880, Accuracy_Val: 0.766\n",
      "Epoch 1245/10000, Loss: 393.119, Accuracy: 0.914, Loss_Val: 160.276, Accuracy_Val: 0.797\n",
      "Epoch 1260/10000, Loss: 379.775, Accuracy: 0.920, Loss_Val: 178.383, Accuracy_Val: 0.776\n",
      "Epoch 1275/10000, Loss: 379.477, Accuracy: 0.923, Loss_Val: 167.436, Accuracy_Val: 0.792\n",
      "Epoch 1290/10000, Loss: 381.830, Accuracy: 0.916, Loss_Val: 171.010, Accuracy_Val: 0.802\n",
      "Epoch 1305/10000, Loss: 373.086, Accuracy: 0.919, Loss_Val: 173.579, Accuracy_Val: 0.787\n",
      "Epoch 1320/10000, Loss: 372.062, Accuracy: 0.925, Loss_Val: 173.537, Accuracy_Val: 0.771\n",
      "Epoch 1335/10000, Loss: 370.753, Accuracy: 0.920, Loss_Val: 180.444, Accuracy_Val: 0.779\n",
      "Epoch 1350/10000, Loss: 366.281, Accuracy: 0.922, Loss_Val: 177.306, Accuracy_Val: 0.779\n",
      "Epoch 1365/10000, Loss: 353.834, Accuracy: 0.928, Loss_Val: 177.503, Accuracy_Val: 0.771\n",
      "Epoch 1380/10000, Loss: 363.325, Accuracy: 0.925, Loss_Val: 175.732, Accuracy_Val: 0.761\n",
      "Epoch 1395/10000, Loss: 362.582, Accuracy: 0.920, Loss_Val: 151.316, Accuracy_Val: 0.810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1410/10000, Loss: 336.229, Accuracy: 0.931, Loss_Val: 165.915, Accuracy_Val: 0.789\n",
      "Epoch 1425/10000, Loss: 337.004, Accuracy: 0.931, Loss_Val: 182.712, Accuracy_Val: 0.766\n",
      "Epoch 1440/10000, Loss: 323.996, Accuracy: 0.927, Loss_Val: 170.251, Accuracy_Val: 0.792\n",
      "Epoch 1455/10000, Loss: 327.897, Accuracy: 0.933, Loss_Val: 152.169, Accuracy_Val: 0.820\n",
      "Epoch 1470/10000, Loss: 312.227, Accuracy: 0.936, Loss_Val: 183.019, Accuracy_Val: 0.766\n",
      "Epoch 1485/10000, Loss: 331.428, Accuracy: 0.929, Loss_Val: 171.895, Accuracy_Val: 0.802\n",
      "Epoch 1500/10000, Loss: 336.026, Accuracy: 0.928, Loss_Val: 168.025, Accuracy_Val: 0.802\n",
      "Epoch 1515/10000, Loss: 304.593, Accuracy: 0.935, Loss_Val: 173.742, Accuracy_Val: 0.769\n",
      "Epoch 1530/10000, Loss: 296.014, Accuracy: 0.943, Loss_Val: 159.895, Accuracy_Val: 0.815\n",
      "Epoch 1545/10000, Loss: 303.215, Accuracy: 0.939, Loss_Val: 171.352, Accuracy_Val: 0.774\n",
      "Epoch 1560/10000, Loss: 291.925, Accuracy: 0.939, Loss_Val: 174.416, Accuracy_Val: 0.779\n",
      "Epoch 1575/10000, Loss: 307.603, Accuracy: 0.933, Loss_Val: 159.811, Accuracy_Val: 0.802\n",
      "Epoch 1590/10000, Loss: 283.795, Accuracy: 0.939, Loss_Val: 180.480, Accuracy_Val: 0.794\n",
      "Epoch 1605/10000, Loss: 282.517, Accuracy: 0.943, Loss_Val: 164.556, Accuracy_Val: 0.787\n",
      "Epoch 1620/10000, Loss: 282.977, Accuracy: 0.940, Loss_Val: 158.686, Accuracy_Val: 0.815\n",
      "Epoch 1635/10000, Loss: 269.387, Accuracy: 0.944, Loss_Val: 175.232, Accuracy_Val: 0.787\n",
      "Epoch 1650/10000, Loss: 280.559, Accuracy: 0.944, Loss_Val: 164.431, Accuracy_Val: 0.812\n",
      "Epoch 1665/10000, Loss: 264.055, Accuracy: 0.949, Loss_Val: 162.836, Accuracy_Val: 0.797\n",
      "Epoch 1680/10000, Loss: 276.346, Accuracy: 0.941, Loss_Val: 160.599, Accuracy_Val: 0.817\n",
      "Epoch 1695/10000, Loss: 271.787, Accuracy: 0.945, Loss_Val: 155.372, Accuracy_Val: 0.820\n",
      "Epoch 1710/10000, Loss: 261.209, Accuracy: 0.949, Loss_Val: 165.156, Accuracy_Val: 0.802\n",
      "Epoch 1725/10000, Loss: 252.671, Accuracy: 0.949, Loss_Val: 163.413, Accuracy_Val: 0.797\n",
      "Epoch 1740/10000, Loss: 257.598, Accuracy: 0.942, Loss_Val: 172.443, Accuracy_Val: 0.779\n",
      "Epoch 1755/10000, Loss: 263.029, Accuracy: 0.948, Loss_Val: 167.930, Accuracy_Val: 0.810\n",
      "Epoch 1770/10000, Loss: 246.220, Accuracy: 0.949, Loss_Val: 181.204, Accuracy_Val: 0.774\n",
      "Epoch 1785/10000, Loss: 221.097, Accuracy: 0.956, Loss_Val: 157.060, Accuracy_Val: 0.820\n",
      "Epoch 1800/10000, Loss: 231.637, Accuracy: 0.954, Loss_Val: 166.505, Accuracy_Val: 0.812\n",
      "Epoch 1815/10000, Loss: 237.843, Accuracy: 0.952, Loss_Val: 162.285, Accuracy_Val: 0.815\n",
      "Epoch 1830/10000, Loss: 231.812, Accuracy: 0.952, Loss_Val: 182.225, Accuracy_Val: 0.771\n",
      "Epoch 1845/10000, Loss: 253.756, Accuracy: 0.951, Loss_Val: 183.989, Accuracy_Val: 0.774\n",
      "Epoch 1860/10000, Loss: 226.226, Accuracy: 0.958, Loss_Val: 159.963, Accuracy_Val: 0.825\n",
      "Epoch 1875/10000, Loss: 236.946, Accuracy: 0.952, Loss_Val: 162.305, Accuracy_Val: 0.812\n",
      "Epoch 1890/10000, Loss: 238.742, Accuracy: 0.949, Loss_Val: 154.345, Accuracy_Val: 0.807\n",
      "Epoch 1905/10000, Loss: 221.839, Accuracy: 0.959, Loss_Val: 160.418, Accuracy_Val: 0.794\n",
      "Epoch 1920/10000, Loss: 204.110, Accuracy: 0.960, Loss_Val: 171.629, Accuracy_Val: 0.789\n",
      "Epoch 1935/10000, Loss: 214.889, Accuracy: 0.957, Loss_Val: 163.010, Accuracy_Val: 0.792\n",
      "Epoch 1950/10000, Loss: 196.487, Accuracy: 0.963, Loss_Val: 173.629, Accuracy_Val: 0.805\n",
      "Epoch 1965/10000, Loss: 210.775, Accuracy: 0.957, Loss_Val: 166.548, Accuracy_Val: 0.797\n",
      "Epoch 1980/10000, Loss: 201.195, Accuracy: 0.963, Loss_Val: 162.483, Accuracy_Val: 0.810\n",
      "Epoch 1995/10000, Loss: 191.931, Accuracy: 0.964, Loss_Val: 171.091, Accuracy_Val: 0.792\n",
      "Epoch 2010/10000, Loss: 187.975, Accuracy: 0.966, Loss_Val: 179.862, Accuracy_Val: 0.789\n",
      "Epoch 2025/10000, Loss: 204.288, Accuracy: 0.963, Loss_Val: 187.830, Accuracy_Val: 0.779\n",
      "Epoch 2040/10000, Loss: 197.390, Accuracy: 0.959, Loss_Val: 170.289, Accuracy_Val: 0.794\n",
      "Epoch 2055/10000, Loss: 182.735, Accuracy: 0.965, Loss_Val: 146.940, Accuracy_Val: 0.817\n",
      "Epoch 2070/10000, Loss: 197.381, Accuracy: 0.963, Loss_Val: 160.641, Accuracy_Val: 0.789\n",
      "Epoch 2085/10000, Loss: 203.599, Accuracy: 0.960, Loss_Val: 153.523, Accuracy_Val: 0.812\n",
      "Epoch 2100/10000, Loss: 197.462, Accuracy: 0.963, Loss_Val: 164.828, Accuracy_Val: 0.794\n",
      "Epoch 2115/10000, Loss: 190.923, Accuracy: 0.962, Loss_Val: 167.471, Accuracy_Val: 0.815\n",
      "Epoch 2130/10000, Loss: 178.547, Accuracy: 0.963, Loss_Val: 164.780, Accuracy_Val: 0.805\n",
      "Epoch 2145/10000, Loss: 185.863, Accuracy: 0.964, Loss_Val: 164.880, Accuracy_Val: 0.794\n",
      "Epoch 2160/10000, Loss: 178.136, Accuracy: 0.969, Loss_Val: 181.715, Accuracy_Val: 0.781\n",
      "Epoch 2175/10000, Loss: 170.696, Accuracy: 0.967, Loss_Val: 180.944, Accuracy_Val: 0.799\n",
      "Epoch 2190/10000, Loss: 171.849, Accuracy: 0.970, Loss_Val: 174.934, Accuracy_Val: 0.792\n",
      "Epoch 2205/10000, Loss: 152.966, Accuracy: 0.974, Loss_Val: 178.316, Accuracy_Val: 0.815\n",
      "Epoch 2220/10000, Loss: 182.609, Accuracy: 0.963, Loss_Val: 167.549, Accuracy_Val: 0.820\n",
      "Epoch 2235/10000, Loss: 154.011, Accuracy: 0.975, Loss_Val: 182.762, Accuracy_Val: 0.781\n",
      "Epoch 2250/10000, Loss: 171.005, Accuracy: 0.962, Loss_Val: 173.825, Accuracy_Val: 0.789\n",
      "Epoch 2265/10000, Loss: 156.248, Accuracy: 0.974, Loss_Val: 168.315, Accuracy_Val: 0.817\n",
      "Epoch 2280/10000, Loss: 146.536, Accuracy: 0.974, Loss_Val: 165.613, Accuracy_Val: 0.807\n",
      "Epoch 2295/10000, Loss: 134.655, Accuracy: 0.974, Loss_Val: 170.238, Accuracy_Val: 0.794\n",
      "Epoch 2310/10000, Loss: 160.212, Accuracy: 0.971, Loss_Val: 171.944, Accuracy_Val: 0.807\n",
      "Epoch 2325/10000, Loss: 163.153, Accuracy: 0.963, Loss_Val: 166.939, Accuracy_Val: 0.817\n",
      "Epoch 2340/10000, Loss: 146.116, Accuracy: 0.973, Loss_Val: 176.909, Accuracy_Val: 0.787\n",
      "Epoch 2355/10000, Loss: 134.267, Accuracy: 0.976, Loss_Val: 162.719, Accuracy_Val: 0.805\n",
      "Epoch 2370/10000, Loss: 153.308, Accuracy: 0.972, Loss_Val: 154.312, Accuracy_Val: 0.815\n",
      "Epoch 2385/10000, Loss: 141.509, Accuracy: 0.977, Loss_Val: 165.891, Accuracy_Val: 0.807\n",
      "Epoch 2400/10000, Loss: 128.949, Accuracy: 0.980, Loss_Val: 194.619, Accuracy_Val: 0.797\n",
      "Epoch 2415/10000, Loss: 134.651, Accuracy: 0.977, Loss_Val: 175.654, Accuracy_Val: 0.807\n",
      "Epoch 2430/10000, Loss: 144.429, Accuracy: 0.974, Loss_Val: 188.530, Accuracy_Val: 0.781\n",
      "Epoch 2445/10000, Loss: 145.076, Accuracy: 0.979, Loss_Val: 149.739, Accuracy_Val: 0.833\n",
      "Epoch 2460/10000, Loss: 128.084, Accuracy: 0.978, Loss_Val: 152.957, Accuracy_Val: 0.815\n",
      "Epoch 2475/10000, Loss: 133.649, Accuracy: 0.975, Loss_Val: 172.111, Accuracy_Val: 0.799\n",
      "Epoch 2490/10000, Loss: 131.325, Accuracy: 0.976, Loss_Val: 169.319, Accuracy_Val: 0.792\n",
      "Epoch 2505/10000, Loss: 139.944, Accuracy: 0.977, Loss_Val: 173.319, Accuracy_Val: 0.805\n",
      "Epoch 2520/10000, Loss: 130.138, Accuracy: 0.979, Loss_Val: 147.984, Accuracy_Val: 0.835\n",
      "Epoch 2535/10000, Loss: 130.437, Accuracy: 0.974, Loss_Val: 167.588, Accuracy_Val: 0.805\n",
      "Epoch 2550/10000, Loss: 123.135, Accuracy: 0.975, Loss_Val: 176.252, Accuracy_Val: 0.812\n",
      "Epoch 2565/10000, Loss: 130.831, Accuracy: 0.977, Loss_Val: 160.123, Accuracy_Val: 0.802\n",
      "Epoch 2580/10000, Loss: 136.722, Accuracy: 0.978, Loss_Val: 174.441, Accuracy_Val: 0.799\n",
      "Epoch 2595/10000, Loss: 138.947, Accuracy: 0.975, Loss_Val: 170.260, Accuracy_Val: 0.817\n",
      "Epoch 2610/10000, Loss: 138.718, Accuracy: 0.971, Loss_Val: 155.724, Accuracy_Val: 0.815\n",
      "Epoch 2625/10000, Loss: 123.322, Accuracy: 0.975, Loss_Val: 185.987, Accuracy_Val: 0.774\n",
      "Epoch 2640/10000, Loss: 110.712, Accuracy: 0.981, Loss_Val: 176.741, Accuracy_Val: 0.805\n",
      "Epoch 2655/10000, Loss: 108.455, Accuracy: 0.980, Loss_Val: 183.361, Accuracy_Val: 0.799\n",
      "Epoch 2670/10000, Loss: 112.745, Accuracy: 0.978, Loss_Val: 170.473, Accuracy_Val: 0.797\n",
      "Epoch 2685/10000, Loss: 120.724, Accuracy: 0.980, Loss_Val: 169.104, Accuracy_Val: 0.825\n",
      "Epoch 2700/10000, Loss: 120.102, Accuracy: 0.981, Loss_Val: 166.426, Accuracy_Val: 0.805\n",
      "Epoch 2715/10000, Loss: 125.242, Accuracy: 0.979, Loss_Val: 187.867, Accuracy_Val: 0.794\n",
      "Epoch 2730/10000, Loss: 119.013, Accuracy: 0.978, Loss_Val: 173.890, Accuracy_Val: 0.784\n",
      "Epoch 2745/10000, Loss: 100.121, Accuracy: 0.984, Loss_Val: 173.181, Accuracy_Val: 0.807\n",
      "Epoch 2760/10000, Loss: 114.302, Accuracy: 0.976, Loss_Val: 160.572, Accuracy_Val: 0.833\n",
      "Epoch 2775/10000, Loss: 111.934, Accuracy: 0.982, Loss_Val: 182.728, Accuracy_Val: 0.805\n",
      "Epoch 2790/10000, Loss: 111.056, Accuracy: 0.979, Loss_Val: 168.490, Accuracy_Val: 0.817\n",
      "Epoch 2805/10000, Loss: 120.263, Accuracy: 0.977, Loss_Val: 197.562, Accuracy_Val: 0.794\n",
      "Epoch 2820/10000, Loss: 94.433, Accuracy: 0.984, Loss_Val: 165.919, Accuracy_Val: 0.817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2835/10000, Loss: 109.979, Accuracy: 0.979, Loss_Val: 174.741, Accuracy_Val: 0.820\n",
      "Epoch 2850/10000, Loss: 94.897, Accuracy: 0.984, Loss_Val: 172.293, Accuracy_Val: 0.815\n",
      "Epoch 2865/10000, Loss: 117.475, Accuracy: 0.982, Loss_Val: 165.519, Accuracy_Val: 0.815\n",
      "Epoch 2880/10000, Loss: 94.756, Accuracy: 0.983, Loss_Val: 174.804, Accuracy_Val: 0.805\n",
      "Epoch 2895/10000, Loss: 99.392, Accuracy: 0.982, Loss_Val: 185.027, Accuracy_Val: 0.781\n",
      "Epoch 2910/10000, Loss: 96.954, Accuracy: 0.980, Loss_Val: 172.744, Accuracy_Val: 0.799\n",
      "Epoch 2925/10000, Loss: 92.955, Accuracy: 0.985, Loss_Val: 171.468, Accuracy_Val: 0.794\n",
      "Epoch 2940/10000, Loss: 91.654, Accuracy: 0.984, Loss_Val: 199.563, Accuracy_Val: 0.792\n",
      "Epoch 2955/10000, Loss: 101.627, Accuracy: 0.979, Loss_Val: 166.387, Accuracy_Val: 0.828\n",
      "Epoch 2970/10000, Loss: 95.430, Accuracy: 0.984, Loss_Val: 167.955, Accuracy_Val: 0.805\n",
      "Epoch 2985/10000, Loss: 87.946, Accuracy: 0.987, Loss_Val: 184.485, Accuracy_Val: 0.802\n",
      "Epoch 3000/10000, Loss: 82.248, Accuracy: 0.987, Loss_Val: 187.323, Accuracy_Val: 0.799\n",
      "Epoch 3015/10000, Loss: 86.509, Accuracy: 0.984, Loss_Val: 180.931, Accuracy_Val: 0.823\n",
      "Epoch 3030/10000, Loss: 87.520, Accuracy: 0.985, Loss_Val: 179.576, Accuracy_Val: 0.815\n",
      "Epoch 3045/10000, Loss: 85.792, Accuracy: 0.984, Loss_Val: 169.510, Accuracy_Val: 0.833\n",
      "Epoch 3060/10000, Loss: 96.640, Accuracy: 0.981, Loss_Val: 171.135, Accuracy_Val: 0.807\n",
      "Epoch 3075/10000, Loss: 94.634, Accuracy: 0.982, Loss_Val: 177.695, Accuracy_Val: 0.805\n",
      "Epoch 3090/10000, Loss: 92.947, Accuracy: 0.985, Loss_Val: 185.850, Accuracy_Val: 0.805\n",
      "Epoch 3105/10000, Loss: 85.716, Accuracy: 0.985, Loss_Val: 175.508, Accuracy_Val: 0.810\n",
      "Epoch 3120/10000, Loss: 84.798, Accuracy: 0.986, Loss_Val: 178.469, Accuracy_Val: 0.825\n",
      "Epoch 3135/10000, Loss: 90.363, Accuracy: 0.985, Loss_Val: 166.970, Accuracy_Val: 0.830\n",
      "Epoch 3150/10000, Loss: 90.567, Accuracy: 0.984, Loss_Val: 173.977, Accuracy_Val: 0.817\n",
      "Epoch 3165/10000, Loss: 103.617, Accuracy: 0.982, Loss_Val: 185.166, Accuracy_Val: 0.810\n",
      "Epoch 3180/10000, Loss: 85.066, Accuracy: 0.985, Loss_Val: 202.407, Accuracy_Val: 0.789\n",
      "Epoch 3195/10000, Loss: 83.628, Accuracy: 0.985, Loss_Val: 195.484, Accuracy_Val: 0.789\n",
      "Epoch 3210/10000, Loss: 92.365, Accuracy: 0.983, Loss_Val: 203.921, Accuracy_Val: 0.792\n",
      "Epoch 3225/10000, Loss: 93.647, Accuracy: 0.983, Loss_Val: 193.142, Accuracy_Val: 0.794\n",
      "Epoch 3240/10000, Loss: 98.314, Accuracy: 0.984, Loss_Val: 188.842, Accuracy_Val: 0.802\n",
      "Epoch 3255/10000, Loss: 82.428, Accuracy: 0.987, Loss_Val: 172.133, Accuracy_Val: 0.823\n",
      "Epoch 3270/10000, Loss: 71.170, Accuracy: 0.986, Loss_Val: 184.948, Accuracy_Val: 0.794\n",
      "Final Model, Loss_Val: 134.307, Accuracy_Val: 0.830\n",
      "Final Model, Loss_Test: 117.277, Accuracy_Test: 0.862\n"
     ]
    }
   ],
   "source": [
    "# NN MODEL WITH RESULTS\n",
    "\n",
    "hidden_neurons = 32\n",
    "n_outputs = 1\n",
    "num_epochs = 10000\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_mfcc, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p = 0.1),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p = 0.1),\n",
    "    torch.nn.Linear(hidden_neurons, n_outputs),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "minimum = 0\n",
    "best_model = None\n",
    "\n",
    "no_improve = 0\n",
    "early_stopping_steps = 49\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(data_train_tensor)\n",
    "        \n",
    "    loss = criterion(y_pred, labels_train_tensor)\n",
    "    \n",
    "    if epoch % 15 == 14:\n",
    "        \n",
    "        y_pred_val = model(data_val_tensor)\n",
    "        loss_val = criterion(y_pred_val, labels_val_tensor)\n",
    "        \n",
    "        #Accuracy \n",
    "        output       = (y_pred > 0.5).float()\n",
    "        correct      = (output == labels_train_tensor).float().sum()\n",
    "        output_val   = (y_pred_val > 0.5).float()\n",
    "        correct_val  = (output_val == labels_val_tensor).float().sum()\n",
    "        accuracy_val = correct_val/labels_val_tensor.shape[0]\n",
    "        \n",
    "        if accuracy_val > minimum:\n",
    "            minimum = accuracy_val\n",
    "            torch.save({'state_dict':model.state_dict(), 'optimizer': optimizer.state_dict()}, 'model.pth.tar')          \n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}, Loss_Val: {:.3f}, Accuracy_Val: {:.3f}\".format(epoch+1,\n",
    "                        num_epochs, loss, correct/labels_train_tensor.shape[0], loss_val, correct_val/labels_val_tensor.shape[0]))  \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # early stopping\n",
    "    if no_improve > early_stopping_steps:\n",
    "        break\n",
    "\n",
    "checkpoint = torch.load('model.pth.tar')         \n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_pred_val = model(data_val_tensor)\n",
    "loss_val = criterion(y_pred_val, labels_val_tensor)\n",
    "output_val  = (y_pred_val > 0.5).float()\n",
    "correct_val = (output_val == labels_val_tensor).float().sum()\n",
    "        \n",
    "print(\"Final Model, Loss_Val: {:.3f}, Accuracy_Val: {:.3f}\".format(loss_val, correct_val/labels_val_tensor.shape[0])) \n",
    "\n",
    "y_pred_test = model(data_test_tensor)\n",
    "loss_test = criterion(y_pred_test, labels_test_tensor)\n",
    "output_test  = (y_pred_test > 0.5).float()\n",
    "correct_test = (output_test == labels_test_tensor).float().sum()\n",
    "        \n",
    "print(\"Final Model, Loss_Test: {:.3f}, Accuracy_Test: {:.3f}\".format(loss_test, correct_test/labels_test_tensor.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5000, Accuracy: 0.843, Accuracy_Val: 0.607\n",
      "Epoch 10/5000, Accuracy: 0.866, Accuracy_Val: 0.635\n",
      "Epoch 15/5000, Accuracy: 0.877, Accuracy_Val: 0.627\n",
      "Epoch 20/5000, Accuracy: 0.877, Accuracy_Val: 0.627\n",
      "Epoch 25/5000, Accuracy: 0.877, Accuracy_Val: 0.648\n",
      "Epoch 30/5000, Accuracy: 0.874, Accuracy_Val: 0.627\n",
      "Epoch 35/5000, Accuracy: 0.871, Accuracy_Val: 0.630\n",
      "Epoch 40/5000, Accuracy: 0.879, Accuracy_Val: 0.656\n",
      "Epoch 45/5000, Accuracy: 0.880, Accuracy_Val: 0.656\n",
      "Epoch 50/5000, Accuracy: 0.872, Accuracy_Val: 0.668\n",
      "Epoch 55/5000, Accuracy: 0.850, Accuracy_Val: 0.632\n",
      "Epoch 60/5000, Accuracy: 0.891, Accuracy_Val: 0.710\n",
      "Epoch 65/5000, Accuracy: 0.897, Accuracy_Val: 0.740\n",
      "Epoch 70/5000, Accuracy: 0.897, Accuracy_Val: 0.748\n",
      "Epoch 75/5000, Accuracy: 0.868, Accuracy_Val: 0.689\n",
      "Epoch 80/5000, Accuracy: 0.887, Accuracy_Val: 0.746\n",
      "Epoch 85/5000, Accuracy: 0.884, Accuracy_Val: 0.743\n",
      "Epoch 90/5000, Accuracy: 0.894, Accuracy_Val: 0.771\n",
      "Epoch 95/5000, Accuracy: 0.879, Accuracy_Val: 0.746\n",
      "Epoch 100/5000, Accuracy: 0.879, Accuracy_Val: 0.743\n",
      "Epoch 105/5000, Accuracy: 0.881, Accuracy_Val: 0.751\n",
      "Epoch 110/5000, Accuracy: 0.926, Accuracy_Val: 0.846\n",
      "Epoch 115/5000, Accuracy: 0.881, Accuracy_Val: 0.751\n",
      "Epoch 120/5000, Accuracy: 0.889, Accuracy_Val: 0.766\n",
      "Epoch 125/5000, Accuracy: 0.884, Accuracy_Val: 0.756\n",
      "Epoch 130/5000, Accuracy: 0.885, Accuracy_Val: 0.758\n",
      "Epoch 135/5000, Accuracy: 0.875, Accuracy_Val: 0.738\n",
      "Epoch 140/5000, Accuracy: 0.936, Accuracy_Val: 0.871\n",
      "Epoch 145/5000, Accuracy: 0.883, Accuracy_Val: 0.756\n",
      "Epoch 150/5000, Accuracy: 0.940, Accuracy_Val: 0.879\n",
      "Epoch 155/5000, Accuracy: 0.889, Accuracy_Val: 0.761\n",
      "Epoch 160/5000, Accuracy: 0.901, Accuracy_Val: 0.802\n",
      "Epoch 165/5000, Accuracy: 0.901, Accuracy_Val: 0.805\n",
      "Epoch 170/5000, Accuracy: 0.955, Accuracy_Val: 0.900\n",
      "Epoch 175/5000, Accuracy: 0.955, Accuracy_Val: 0.897\n",
      "Epoch 180/5000, Accuracy: 0.875, Accuracy_Val: 0.751\n",
      "Epoch 185/5000, Accuracy: 0.957, Accuracy_Val: 0.897\n",
      "Epoch 190/5000, Accuracy: 0.958, Accuracy_Val: 0.897\n",
      "Epoch 195/5000, Accuracy: 0.883, Accuracy_Val: 0.761\n",
      "Epoch 200/5000, Accuracy: 0.960, Accuracy_Val: 0.897\n",
      "Epoch 205/5000, Accuracy: 0.959, Accuracy_Val: 0.900\n",
      "Epoch 210/5000, Accuracy: 0.959, Accuracy_Val: 0.897\n",
      "Epoch 215/5000, Accuracy: 0.958, Accuracy_Val: 0.895\n",
      "Epoch 220/5000, Accuracy: 0.878, Accuracy_Val: 0.751\n",
      "Epoch 225/5000, Accuracy: 0.873, Accuracy_Val: 0.746\n",
      "Epoch 230/5000, Accuracy: 0.877, Accuracy_Val: 0.748\n",
      "Epoch 235/5000, Accuracy: 0.882, Accuracy_Val: 0.753\n",
      "Epoch 240/5000, Accuracy: 0.922, Accuracy_Val: 0.851\n",
      "Epoch 245/5000, Accuracy: 0.881, Accuracy_Val: 0.753\n",
      "Epoch 250/5000, Accuracy: 0.963, Accuracy_Val: 0.897\n",
      "Epoch 255/5000, Accuracy: 0.882, Accuracy_Val: 0.753\n",
      "Epoch 260/5000, Accuracy: 0.966, Accuracy_Val: 0.897\n",
      "Epoch 265/5000, Accuracy: 0.966, Accuracy_Val: 0.897\n",
      "Epoch 270/5000, Accuracy: 0.964, Accuracy_Val: 0.897\n",
      "Epoch 275/5000, Accuracy: 0.902, Accuracy_Val: 0.802\n",
      "Epoch 280/5000, Accuracy: 0.962, Accuracy_Val: 0.897\n",
      "Epoch 285/5000, Accuracy: 0.956, Accuracy_Val: 0.897\n",
      "Epoch 290/5000, Accuracy: 0.951, Accuracy_Val: 0.887\n",
      "Epoch 295/5000, Accuracy: 0.885, Accuracy_Val: 0.753\n",
      "Epoch 300/5000, Accuracy: 0.957, Accuracy_Val: 0.889\n",
      "Epoch 305/5000, Accuracy: 0.907, Accuracy_Val: 0.810\n",
      "Epoch 310/5000, Accuracy: 0.961, Accuracy_Val: 0.887\n",
      "Epoch 315/5000, Accuracy: 0.905, Accuracy_Val: 0.807\n",
      "Epoch 320/5000, Accuracy: 0.903, Accuracy_Val: 0.805\n",
      "Best Result, Accuracy_Val: 0.900\n",
      "Best Result, Accuracy_Test: 0.875\n"
     ]
    }
   ],
   "source": [
    "# SVM MODEL WITH RESULTS\n",
    "\n",
    "dim = 39\n",
    "w = torch.autograd.Variable(torch.rand(dim), requires_grad=True)\n",
    "b = torch.autograd.Variable(torch.rand(1),   requires_grad=True)\n",
    "\n",
    "step_size = 3e-5\n",
    "num_epochs = 5000\n",
    "minibatch_size = 20\n",
    "\n",
    "w_best = None\n",
    "b_best = None\n",
    "\n",
    "minimum = 0\n",
    "no_improve = 0\n",
    "early_stopping_steps = 29 \n",
    "\n",
    "def accuracy(X, y):\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        y_predicted = int(np.sign((torch.dot(w, X[i]) - b).detach().numpy()[0]))\n",
    "        if y_predicted == y[i]: correct += 1\n",
    "    return float(correct)/len(y)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inds = [i for i in range(len(data_train_tensor))]\n",
    "    for i in range(len(inds)):\n",
    "        L = max(0, 1 - labels_train_svm_tensor[inds[i]] * (torch.dot(w, data_train_tensor[inds[i]]) - b))\n",
    "        if L != 0: # if the loss is zero, Pytorch leaves the variables as a float 0.0, so we can't call backward() on it\n",
    "            L.backward()\n",
    "            w.data -= step_size * w.grad.data # step\n",
    "            b.data -= step_size * b.grad.data # step\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "    \n",
    "    if epoch % 5 == 4:\n",
    "        accuracy_val = accuracy(data_val_tensor, labels_val_svm_tensor)\n",
    "        \n",
    "        if accuracy_val > minimum:\n",
    "            minimum = accuracy_val\n",
    "            w_best = copy.deepcopy(w)\n",
    "            b_best = copy.deepcopy(b)\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        print(\"Epoch {}/{}, Accuracy: {:.3f}, Accuracy_Val: {:.3f}\".format(epoch+1, num_epochs, \n",
    "                        accuracy(data_train_tensor, labels_train_svm_tensor), accuracy(data_val_tensor, labels_val_svm_tensor)))  \n",
    "    \n",
    "    # early stopping\n",
    "    if no_improve > early_stopping_steps:\n",
    "        break\n",
    "\n",
    "w = w_best\n",
    "b = b_best\n",
    "\n",
    "print(\"Best Result, Accuracy_Val: {:.3f}\".format(accuracy(data_val_tensor, labels_val_svm_tensor)))  \n",
    "print(\"Best Result, Accuracy_Test: {:.3f}\".format(accuracy(data_test_tensor, labels_test_svm_tensor)))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
