{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./csv/features.csv doesn't exists\n",
      "Features will be calculated\n"
     ]
    }
   ],
   "source": [
    "# CREATE A FOLDER NAMED 'csv' IN THE CURRENT PATH, BEFORE RUNNING THE NOTEBOOK\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import csv\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "\n",
    "n_mfcc = 39\n",
    "csv_file_save = './csv/features.csv'\n",
    "calculate_csv = None\n",
    "\n",
    "if os.path.exists(csv_file_save):\n",
    "    print (\"File \" + csv_file_save + \" exists\")\n",
    "    print (\"Features won't be recalculated\")\n",
    "    calculate_csv = False\n",
    "else:\n",
    "    print (\"File \" + csv_file_save + \" doesn't exists\")\n",
    "    print (\"Features will be calculated\")\n",
    "    calculate_csv = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract info speakers \n",
    "\n",
    "file_speaker = \"./LibriSpeech/SPEAKERS.TXT\"\n",
    "speakers = []\n",
    "\n",
    "f = open(file_speaker, \"r\")\n",
    "for line in f:\n",
    "    if line[0] == \";\":\n",
    "        continue\n",
    "    else:\n",
    "        speakers.append( str.rstrip(line) ) # rstrip to remove \\n at the end of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14   | F | train-clean-360  | 25.03 | Kristin LeMoine',\n",
       " '16   | F | train-clean-360  | 25.11 | Alys AtteWater',\n",
       " '17   | M | train-clean-360  | 25.04 | Gord Mackenzie',\n",
       " '19   | F | train-clean-100  | 25.19 | Kara Shallenberg',\n",
       " '20   | F | train-other-500  | 30.07 | Gesine',\n",
       " '22   | F | train-clean-360  | 25.14 | Michelle Crandall',\n",
       " '23   | F | train-clean-360  | 25.23 | Anita Roy Dobbs',\n",
       " '25   | M | train-other-500  | 30.16 | John Gonzalez',\n",
       " '26   | M | train-clean-100  | 25.08 | Denny Sayers',\n",
       " '27   | M | train-clean-100  | 20.14 | Sean McKinley']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract speakers gender \n",
    "# store in dictionary and in list to choose train and test speakers\n",
    "\n",
    "dict_speakers = {}\n",
    "list_speakers = []\n",
    "for speaker in speakers:\n",
    "    speaker_split = speaker.split()\n",
    "    speaker_split = [word for word in speaker_split if word != \"|\"]\n",
    "    \n",
    "    # indexes = 0 : id, 1 : gender, 2 : dataset\n",
    "    if speaker_split[2] == \"dev-clean\":\n",
    "        dict_speakers[speaker_split[0]] = speaker_split[1]\n",
    "        list_speakers.append(speaker_split[0])\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'84': 'F',\n",
       " '174': 'M',\n",
       " '251': 'M',\n",
       " '422': 'M',\n",
       " '652': 'M',\n",
       " '777': 'M',\n",
       " '1272': 'M',\n",
       " '1462': 'F',\n",
       " '1673': 'F',\n",
       " '1919': 'F',\n",
       " '1988': 'F',\n",
       " '1993': 'F',\n",
       " '2035': 'F',\n",
       " '2078': 'M',\n",
       " '2086': 'M',\n",
       " '2277': 'F',\n",
       " '2412': 'F',\n",
       " '2428': 'M',\n",
       " '2803': 'M',\n",
       " '2902': 'M',\n",
       " '3000': 'M',\n",
       " '3081': 'F',\n",
       " '3170': 'M',\n",
       " '3536': 'F',\n",
       " '3576': 'F',\n",
       " '3752': 'M',\n",
       " '3853': 'F',\n",
       " '5338': 'F',\n",
       " '5536': 'M',\n",
       " '5694': 'M',\n",
       " '5895': 'F',\n",
       " '6241': 'M',\n",
       " '6295': 'M',\n",
       " '6313': 'F',\n",
       " '6319': 'F',\n",
       " '6345': 'F',\n",
       " '7850': 'F',\n",
       " '7976': 'M',\n",
       " '8297': 'M',\n",
       " '8842': 'F'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_speakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get audio files info : name and path \n",
    "\n",
    "if calculate_csv:\n",
    "    audio_files = []\n",
    "\n",
    "    root = \"./\"\n",
    "    path = os.path.join(root, \"LibriSpeech\")\n",
    "\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path):\n",
    "        for file in filenames:\n",
    "            if file[-5:] == \".flac\":\n",
    "                audio_files.append({\"dirpath\": dirpath, \"filename\": file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if calculate_csv:\n",
    "    len(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if calculate_csv:\n",
    "    audio_files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels genders (target) for each file \n",
    "\n",
    "if calculate_csv:\n",
    "    gender_labels = []\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "        file = audio_file[\"filename\"]\n",
    "        index = 0\n",
    "        for char in file:\n",
    "            if char != \"-\":\n",
    "                index += 1\n",
    "            else:\n",
    "                break\n",
    "        id_speaker = file[:index]\n",
    "        audio_file[\"id_speaker\"] = id_speaker\n",
    "\n",
    "        gender_labels.append(dict_speakers[id_speaker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_csv:\n",
    "    len(gender_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features file 100/2703\n",
      "Extracting features file 200/2703\n",
      "Extracting features file 300/2703\n",
      "Extracting features file 400/2703\n",
      "Extracting features file 500/2703\n",
      "Extracting features file 600/2703\n",
      "Extracting features file 700/2703\n",
      "Extracting features file 800/2703\n",
      "Extracting features file 900/2703\n",
      "Extracting features file 1000/2703\n",
      "Extracting features file 1100/2703\n",
      "Extracting features file 1200/2703\n",
      "Extracting features file 1300/2703\n",
      "Extracting features file 1400/2703\n",
      "Extracting features file 1500/2703\n",
      "Extracting features file 1600/2703\n",
      "Extracting features file 1700/2703\n",
      "Extracting features file 1800/2703\n",
      "Extracting features file 1900/2703\n",
      "Extracting features file 2000/2703\n",
      "Extracting features file 2100/2703\n",
      "Extracting features file 2200/2703\n",
      "Extracting features file 2300/2703\n",
      "Extracting features file 2400/2703\n",
      "Extracting features file 2500/2703\n",
      "Extracting features file 2600/2703\n",
      "Extracting features file 2700/2703\n",
      "End of extracting features\n"
     ]
    }
   ],
   "source": [
    "# extract mfcc features and make mean for each feature\n",
    "\n",
    "if calculate_csv:\n",
    "\n",
    "    input_features = []\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    for audio_file in audio_files:\n",
    "\n",
    "        counter += 1\n",
    "        if counter % 100 == 0:\n",
    "            print(\"Extracting features file \" + str(counter) + \"/\" + str(len(audio_files)))\n",
    "\n",
    "        directory = audio_file[\"dirpath\"]\n",
    "        filename = audio_file[\"filename\"]\n",
    "\n",
    "        y, sr = librosa.load(directory + \"/\" + filename)\n",
    "        hop_length = 512\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=n_mfcc)\n",
    "        mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "        input_features.append(mfccs_processed)\n",
    "\n",
    "    print(\"End of extracting features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_csv:\n",
    "    len(input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calculate_csv:\n",
    "    len(input_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing row 500/2703\n",
      "Writing row 1000/2703\n",
      "Writing row 1500/2703\n",
      "Writing row 2000/2703\n",
      "Writing row 2500/2703\n",
      "End of writing csv\n"
     ]
    }
   ],
   "source": [
    "# save features on csv with additional info and labels\n",
    "\n",
    "if calculate_csv:\n",
    "\n",
    "    with open(csv_file_save, 'w', newline='') as csvfile:\n",
    "        feat_writer = csv.writer(csvfile, delimiter=',',\n",
    "                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        index = 0\n",
    "\n",
    "        row_to_write = ['label', 'label_value', 'id_speaker']\n",
    "        for f in range(n_mfcc):\n",
    "            row_to_write.append('f' + str(f))\n",
    "\n",
    "        feat_writer.writerow(row_to_write)\n",
    "\n",
    "        for input_feature in input_features:\n",
    "\n",
    "            class_label = gender_labels[index]\n",
    "            if class_label == \"M\":\n",
    "                class_label = 0\n",
    "            else:\n",
    "                class_label = 1\n",
    "\n",
    "            row_to_write = [class_label, gender_labels[index], audio_files[index][\"id_speaker\"]]\n",
    "\n",
    "            index += 1\n",
    "\n",
    "            if index % 500 == 0:\n",
    "                print(\"Writing row \" + str(index) + \"/\" + str(len(audio_files)))\n",
    "            for features in input_feature:\n",
    "                row_to_write.append(features)\n",
    "\n",
    "            feat_writer.writerow(row_to_write)\n",
    "    print(\"End of writing csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6319, 84, 777, 6313, 1272, 174, 422, 5338, 2803, 7976, 6345, 3536, 5895, 6295, 3752, 3576, 5694, 3081, 3170, 2086, 7850, 2277, 652, 5536, 1993, 8842, 1919, 3000]\n",
      "[1462, 6241, 8297, 3853, 2078, 2412]\n",
      "[2428, 251, 2035, 1673, 2902, 1988]\n"
     ]
    }
   ],
   "source": [
    "# choose speakers to put in each dataset\n",
    "\n",
    "random.shuffle(list_speakers)\n",
    "\n",
    "speakers_train = []\n",
    "speakers_val   = []\n",
    "speakers_test  = []\n",
    "count_males   = 0\n",
    "count_females = 0 \n",
    "n_speakers = len(list_speakers)\n",
    "n_speakers_for_gender_train = (n_speakers / 2) * 0.7\n",
    "n_speakers_for_gender_train_val = (n_speakers / 2) * 0.85\n",
    "\n",
    "for speaker in list_speakers:\n",
    "    gender = dict_speakers[speaker]\n",
    "    if gender == 'M':\n",
    "        if count_males < n_speakers_for_gender_train: \n",
    "            speakers_train.append(int(speaker))\n",
    "        elif count_males < n_speakers_for_gender_train_val: \n",
    "            speakers_val.append(int(speaker))\n",
    "        else:\n",
    "            speakers_test.append(int(speaker))\n",
    "        count_males += 1\n",
    "    elif gender == 'F':\n",
    "        if count_females < n_speakers_for_gender_train: \n",
    "            speakers_train.append(int(speaker))\n",
    "        elif count_females < n_speakers_for_gender_train_val: \n",
    "            speakers_val.append(int(speaker))\n",
    "        else:\n",
    "            speakers_test.append(int(speaker))\n",
    "        count_females += 1\n",
    "    \n",
    "print(speakers_train)\n",
    "print(speakers_val)\n",
    "print(speakers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1895, 1)\n",
      "(1895, 39)\n",
      "(414, 1)\n",
      "(414, 39)\n",
      "(394, 1)\n",
      "(394, 39)\n",
      "(1895, 1)\n",
      "(414, 1)\n",
      "(394, 1)\n"
     ]
    }
   ],
   "source": [
    "# read csv to get inputs and targets\n",
    "\n",
    "my_data = np.genfromtxt(csv_file_save, delimiter=',', skip_header=1)\n",
    "\n",
    "labels_train = []\n",
    "data_train   = []\n",
    "labels_val   = []\n",
    "data_val     = []\n",
    "labels_test  = []\n",
    "data_test    = []\n",
    "labels_train_svm = []\n",
    "labels_val_svm = []\n",
    "labels_test_svm  = []\n",
    "\n",
    "for row in my_data:\n",
    "    if row[2] in speakers_train:\n",
    "        labels_train.append([row[0]])\n",
    "        data_train.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_train_svm.append([1])\n",
    "        else:\n",
    "            labels_train_svm.append([-1])\n",
    "    elif row[2] in speakers_val:\n",
    "        labels_val.append([row[0]])\n",
    "        data_val.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_val_svm.append([1])\n",
    "        else:\n",
    "            labels_val_svm.append([-1])\n",
    "    else:\n",
    "        labels_test.append([row[0]])\n",
    "        data_test.append(row[3:])\n",
    "        if row[0] == 1:\n",
    "            labels_test_svm.append([1])\n",
    "        else:\n",
    "            labels_test_svm.append([-1])\n",
    "\n",
    "data_train = list(zip(labels_train, data_train, labels_train_svm))\n",
    "random.shuffle(data_train)\n",
    "labels_train, data_train, labels_train_svm = zip(*data_train)\n",
    "\n",
    "data_val = list(zip(labels_val, data_val, labels_val_svm))\n",
    "random.shuffle(data_val)\n",
    "labels_val, data_val, labels_val_svm = zip(*data_val)\n",
    "\n",
    "data_test = list(zip(labels_test, data_test, labels_test_svm))\n",
    "random.shuffle(data_test)\n",
    "labels_test, data_test, labels_test_svm = zip(*data_test)\n",
    "\n",
    "labels_train      = np.array(labels_train)\n",
    "data_train        = np.array(data_train)\n",
    "labels_val        = np.array(labels_val)\n",
    "data_val          = np.array(data_val)\n",
    "labels_test       = np.array(labels_test)\n",
    "data_test         = np.array(data_test)\n",
    "labels_train_svm  = np.array(labels_train_svm)\n",
    "labels_val_svm    = np.array(labels_val_svm)\n",
    "labels_test_svm   = np.array(labels_test_svm)\n",
    "\n",
    "print(labels_train.shape)\n",
    "print(data_train.shape)\n",
    "print(labels_val.shape)\n",
    "print(data_val.shape)\n",
    "print(labels_test.shape)\n",
    "print(data_test.shape)\n",
    "print(labels_train_svm.shape)\n",
    "print(labels_val_svm.shape)\n",
    "print(labels_test_svm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1895, 39]) torch.Size([1895, 1])\n",
      "torch.Size([414, 39]) torch.Size([414, 1])\n",
      "torch.Size([394, 39]) torch.Size([394, 1])\n"
     ]
    }
   ],
   "source": [
    "# cast data to tensor\n",
    "\n",
    "data_train_tensor   = torch.from_numpy(data_train).float()\n",
    "labels_train_tensor = torch.from_numpy(labels_train).float()\n",
    "data_val_tensor   = torch.from_numpy(data_val).float()\n",
    "labels_val_tensor = torch.from_numpy(labels_val).float()\n",
    "data_test_tensor    = torch.from_numpy(data_test).float()\n",
    "labels_test_tensor  = torch.from_numpy(labels_test).float()\n",
    "\n",
    "print(data_train_tensor.shape, labels_train_tensor.shape)\n",
    "print(data_val_tensor.shape, labels_val_tensor.shape)\n",
    "print(data_test_tensor.shape, labels_test_tensor.shape)\n",
    "\n",
    "labels_train_svm_tensor = torch.from_numpy(labels_train_svm).float()\n",
    "labels_val_svm_tensor   = torch.from_numpy(labels_val_svm).float()\n",
    "labels_test_svm_tensor  = torch.from_numpy(labels_test_svm).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Val: 0.635\n",
      "Accuracy_Test: 0.660\n"
     ]
    }
   ],
   "source": [
    "# kNN MODEL WITH RESULTS\n",
    "\n",
    "label_pred_val = []\n",
    "\n",
    "for val_data in data_val_tensor:\n",
    "    dist = torch.norm(data_train_tensor - val_data, dim=1, p=None)\n",
    "    knn  = dist.topk(3, largest=False)\n",
    "    \n",
    "    result = 0\n",
    "    for index in knn.indices:\n",
    "        result += int(labels_train_tensor[index])\n",
    "    result = (result / 3)\n",
    "    \n",
    "    label_pred_val.append([result])\n",
    "\n",
    "label_pred_val = torch.as_tensor(label_pred_val)\n",
    "\n",
    "# Accuracy test \n",
    "output_val  = (label_pred_val > 0.5).float()\n",
    "correct_val = (output_val == labels_val_tensor).float().sum()\n",
    "\n",
    "print(\"Accuracy_Val: {:.3f}\".format(correct_val/labels_val_tensor.shape[0]))\n",
    "\n",
    "label_pred_test = []\n",
    "\n",
    "for test_data in data_test_tensor:\n",
    "    dist = torch.norm(data_train_tensor - test_data, dim=1, p=None)\n",
    "    knn = dist.topk(3, largest=False)\n",
    "    \n",
    "    result = 0\n",
    "    for index in knn.indices:\n",
    "        result += int(labels_train_tensor[index])\n",
    "    result = (result / 3)\n",
    "    \n",
    "    label_pred_test.append([result])\n",
    "\n",
    "label_pred_test = torch.as_tensor(label_pred_test)\n",
    "\n",
    "# Accuracy test \n",
    "output_test  = (label_pred_test > 0.5).float()\n",
    "correct_test = (output_test == labels_test_tensor).float().sum()\n",
    "\n",
    "print(\"Accuracy_Test: {:.3f}\".format(correct_test/labels_test_tensor.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/10000, Loss: 3825.343, Accuracy: 0.476, Loss_Val: 749.147, Accuracy_Val: 0.473\n",
      "Epoch 30/10000, Loss: 3524.017, Accuracy: 0.478, Loss_Val: 717.267, Accuracy_Val: 0.510\n",
      "Epoch 45/10000, Loss: 3504.206, Accuracy: 0.484, Loss_Val: 653.144, Accuracy_Val: 0.527\n",
      "Epoch 60/10000, Loss: 3292.731, Accuracy: 0.488, Loss_Val: 652.622, Accuracy_Val: 0.512\n",
      "Epoch 75/10000, Loss: 2911.971, Accuracy: 0.507, Loss_Val: 595.765, Accuracy_Val: 0.527\n",
      "Epoch 90/10000, Loss: 2963.117, Accuracy: 0.495, Loss_Val: 607.702, Accuracy_Val: 0.519\n",
      "Epoch 105/10000, Loss: 2842.059, Accuracy: 0.515, Loss_Val: 545.742, Accuracy_Val: 0.534\n",
      "Epoch 120/10000, Loss: 2735.428, Accuracy: 0.522, Loss_Val: 545.086, Accuracy_Val: 0.541\n",
      "Epoch 135/10000, Loss: 2539.760, Accuracy: 0.525, Loss_Val: 518.706, Accuracy_Val: 0.568\n",
      "Epoch 150/10000, Loss: 2697.585, Accuracy: 0.510, Loss_Val: 490.439, Accuracy_Val: 0.558\n",
      "Epoch 165/10000, Loss: 2551.578, Accuracy: 0.513, Loss_Val: 508.600, Accuracy_Val: 0.548\n",
      "Epoch 180/10000, Loss: 2367.143, Accuracy: 0.538, Loss_Val: 480.392, Accuracy_Val: 0.543\n",
      "Epoch 195/10000, Loss: 2331.049, Accuracy: 0.527, Loss_Val: 498.912, Accuracy_Val: 0.539\n",
      "Epoch 210/10000, Loss: 2196.169, Accuracy: 0.548, Loss_Val: 434.523, Accuracy_Val: 0.570\n",
      "Epoch 225/10000, Loss: 2091.749, Accuracy: 0.564, Loss_Val: 453.584, Accuracy_Val: 0.560\n",
      "Epoch 240/10000, Loss: 1978.976, Accuracy: 0.553, Loss_Val: 398.347, Accuracy_Val: 0.592\n",
      "Epoch 255/10000, Loss: 1983.528, Accuracy: 0.569, Loss_Val: 408.674, Accuracy_Val: 0.575\n",
      "Epoch 270/10000, Loss: 1964.530, Accuracy: 0.571, Loss_Val: 410.911, Accuracy_Val: 0.572\n",
      "Epoch 285/10000, Loss: 1888.849, Accuracy: 0.571, Loss_Val: 378.636, Accuracy_Val: 0.582\n",
      "Epoch 300/10000, Loss: 1781.112, Accuracy: 0.600, Loss_Val: 374.516, Accuracy_Val: 0.597\n",
      "Epoch 315/10000, Loss: 1726.898, Accuracy: 0.597, Loss_Val: 382.946, Accuracy_Val: 0.597\n",
      "Epoch 330/10000, Loss: 1683.183, Accuracy: 0.609, Loss_Val: 371.082, Accuracy_Val: 0.609\n",
      "Epoch 345/10000, Loss: 1668.683, Accuracy: 0.600, Loss_Val: 372.142, Accuracy_Val: 0.604\n",
      "Epoch 360/10000, Loss: 1522.161, Accuracy: 0.615, Loss_Val: 368.246, Accuracy_Val: 0.580\n",
      "Epoch 375/10000, Loss: 1487.065, Accuracy: 0.639, Loss_Val: 352.919, Accuracy_Val: 0.601\n",
      "Epoch 390/10000, Loss: 1466.036, Accuracy: 0.644, Loss_Val: 357.145, Accuracy_Val: 0.609\n",
      "Epoch 405/10000, Loss: 1430.281, Accuracy: 0.647, Loss_Val: 320.105, Accuracy_Val: 0.645\n",
      "Epoch 420/10000, Loss: 1378.090, Accuracy: 0.639, Loss_Val: 340.356, Accuracy_Val: 0.597\n",
      "Epoch 435/10000, Loss: 1356.242, Accuracy: 0.646, Loss_Val: 344.835, Accuracy_Val: 0.616\n",
      "Epoch 450/10000, Loss: 1300.242, Accuracy: 0.684, Loss_Val: 309.101, Accuracy_Val: 0.652\n",
      "Epoch 465/10000, Loss: 1300.334, Accuracy: 0.665, Loss_Val: 311.524, Accuracy_Val: 0.626\n",
      "Epoch 480/10000, Loss: 1282.594, Accuracy: 0.679, Loss_Val: 320.277, Accuracy_Val: 0.640\n",
      "Epoch 495/10000, Loss: 1207.808, Accuracy: 0.701, Loss_Val: 306.771, Accuracy_Val: 0.657\n",
      "Epoch 510/10000, Loss: 1194.530, Accuracy: 0.702, Loss_Val: 305.507, Accuracy_Val: 0.652\n",
      "Epoch 525/10000, Loss: 1148.950, Accuracy: 0.702, Loss_Val: 303.939, Accuracy_Val: 0.611\n",
      "Epoch 540/10000, Loss: 1128.703, Accuracy: 0.713, Loss_Val: 331.026, Accuracy_Val: 0.604\n",
      "Epoch 555/10000, Loss: 1163.675, Accuracy: 0.708, Loss_Val: 289.929, Accuracy_Val: 0.662\n",
      "Epoch 570/10000, Loss: 1126.637, Accuracy: 0.709, Loss_Val: 301.361, Accuracy_Val: 0.643\n",
      "Epoch 585/10000, Loss: 1094.214, Accuracy: 0.726, Loss_Val: 295.286, Accuracy_Val: 0.664\n",
      "Epoch 600/10000, Loss: 1066.187, Accuracy: 0.730, Loss_Val: 281.869, Accuracy_Val: 0.659\n",
      "Epoch 615/10000, Loss: 976.902, Accuracy: 0.765, Loss_Val: 323.601, Accuracy_Val: 0.633\n",
      "Epoch 630/10000, Loss: 1045.279, Accuracy: 0.739, Loss_Val: 297.326, Accuracy_Val: 0.659\n",
      "Epoch 645/10000, Loss: 966.453, Accuracy: 0.760, Loss_Val: 297.377, Accuracy_Val: 0.647\n",
      "Epoch 660/10000, Loss: 960.763, Accuracy: 0.754, Loss_Val: 295.328, Accuracy_Val: 0.669\n",
      "Epoch 675/10000, Loss: 980.559, Accuracy: 0.750, Loss_Val: 282.831, Accuracy_Val: 0.671\n",
      "Epoch 690/10000, Loss: 992.514, Accuracy: 0.752, Loss_Val: 297.085, Accuracy_Val: 0.650\n",
      "Epoch 705/10000, Loss: 971.383, Accuracy: 0.762, Loss_Val: 291.208, Accuracy_Val: 0.655\n",
      "Epoch 720/10000, Loss: 966.382, Accuracy: 0.755, Loss_Val: 316.447, Accuracy_Val: 0.640\n",
      "Epoch 735/10000, Loss: 918.439, Accuracy: 0.776, Loss_Val: 276.185, Accuracy_Val: 0.676\n",
      "Epoch 750/10000, Loss: 950.938, Accuracy: 0.768, Loss_Val: 294.887, Accuracy_Val: 0.647\n",
      "Epoch 765/10000, Loss: 876.339, Accuracy: 0.784, Loss_Val: 277.080, Accuracy_Val: 0.650\n",
      "Epoch 780/10000, Loss: 920.956, Accuracy: 0.782, Loss_Val: 267.756, Accuracy_Val: 0.679\n",
      "Epoch 795/10000, Loss: 918.694, Accuracy: 0.772, Loss_Val: 292.154, Accuracy_Val: 0.674\n",
      "Epoch 810/10000, Loss: 903.812, Accuracy: 0.786, Loss_Val: 286.154, Accuracy_Val: 0.671\n",
      "Epoch 825/10000, Loss: 889.048, Accuracy: 0.782, Loss_Val: 282.153, Accuracy_Val: 0.640\n",
      "Epoch 840/10000, Loss: 836.890, Accuracy: 0.786, Loss_Val: 286.005, Accuracy_Val: 0.633\n",
      "Epoch 855/10000, Loss: 849.962, Accuracy: 0.790, Loss_Val: 257.457, Accuracy_Val: 0.698\n",
      "Epoch 870/10000, Loss: 816.948, Accuracy: 0.800, Loss_Val: 280.026, Accuracy_Val: 0.659\n",
      "Epoch 885/10000, Loss: 809.248, Accuracy: 0.808, Loss_Val: 242.201, Accuracy_Val: 0.698\n",
      "Epoch 900/10000, Loss: 790.692, Accuracy: 0.816, Loss_Val: 247.122, Accuracy_Val: 0.705\n",
      "Epoch 915/10000, Loss: 816.434, Accuracy: 0.807, Loss_Val: 259.761, Accuracy_Val: 0.679\n",
      "Epoch 930/10000, Loss: 791.199, Accuracy: 0.814, Loss_Val: 275.584, Accuracy_Val: 0.688\n",
      "Epoch 945/10000, Loss: 794.634, Accuracy: 0.806, Loss_Val: 260.561, Accuracy_Val: 0.684\n",
      "Epoch 960/10000, Loss: 786.590, Accuracy: 0.808, Loss_Val: 251.634, Accuracy_Val: 0.708\n",
      "Epoch 975/10000, Loss: 746.279, Accuracy: 0.822, Loss_Val: 246.612, Accuracy_Val: 0.700\n",
      "Epoch 990/10000, Loss: 757.923, Accuracy: 0.819, Loss_Val: 260.064, Accuracy_Val: 0.691\n",
      "Epoch 1005/10000, Loss: 754.607, Accuracy: 0.820, Loss_Val: 262.268, Accuracy_Val: 0.662\n",
      "Epoch 1020/10000, Loss: 746.899, Accuracy: 0.807, Loss_Val: 243.670, Accuracy_Val: 0.700\n",
      "Epoch 1035/10000, Loss: 758.100, Accuracy: 0.810, Loss_Val: 251.871, Accuracy_Val: 0.684\n",
      "Epoch 1050/10000, Loss: 711.653, Accuracy: 0.828, Loss_Val: 276.053, Accuracy_Val: 0.686\n",
      "Epoch 1065/10000, Loss: 782.487, Accuracy: 0.819, Loss_Val: 260.595, Accuracy_Val: 0.671\n",
      "Epoch 1080/10000, Loss: 752.199, Accuracy: 0.817, Loss_Val: 265.115, Accuracy_Val: 0.686\n",
      "Epoch 1095/10000, Loss: 729.553, Accuracy: 0.833, Loss_Val: 235.327, Accuracy_Val: 0.717\n",
      "Epoch 1110/10000, Loss: 706.521, Accuracy: 0.835, Loss_Val: 278.564, Accuracy_Val: 0.674\n",
      "Epoch 1125/10000, Loss: 687.463, Accuracy: 0.839, Loss_Val: 256.706, Accuracy_Val: 0.698\n",
      "Epoch 1140/10000, Loss: 671.121, Accuracy: 0.846, Loss_Val: 272.711, Accuracy_Val: 0.652\n",
      "Epoch 1155/10000, Loss: 719.201, Accuracy: 0.832, Loss_Val: 271.488, Accuracy_Val: 0.664\n",
      "Epoch 1170/10000, Loss: 659.604, Accuracy: 0.842, Loss_Val: 247.007, Accuracy_Val: 0.691\n",
      "Epoch 1185/10000, Loss: 659.574, Accuracy: 0.842, Loss_Val: 252.384, Accuracy_Val: 0.655\n",
      "Epoch 1200/10000, Loss: 672.531, Accuracy: 0.848, Loss_Val: 271.040, Accuracy_Val: 0.664\n",
      "Epoch 1215/10000, Loss: 679.671, Accuracy: 0.828, Loss_Val: 247.640, Accuracy_Val: 0.686\n",
      "Epoch 1230/10000, Loss: 645.868, Accuracy: 0.846, Loss_Val: 247.670, Accuracy_Val: 0.696\n",
      "Epoch 1245/10000, Loss: 638.908, Accuracy: 0.858, Loss_Val: 249.331, Accuracy_Val: 0.703\n",
      "Epoch 1260/10000, Loss: 652.021, Accuracy: 0.848, Loss_Val: 252.115, Accuracy_Val: 0.686\n",
      "Epoch 1275/10000, Loss: 634.057, Accuracy: 0.846, Loss_Val: 244.015, Accuracy_Val: 0.715\n",
      "Epoch 1290/10000, Loss: 636.735, Accuracy: 0.841, Loss_Val: 243.720, Accuracy_Val: 0.686\n",
      "Epoch 1305/10000, Loss: 619.159, Accuracy: 0.848, Loss_Val: 256.912, Accuracy_Val: 0.664\n",
      "Epoch 1320/10000, Loss: 646.767, Accuracy: 0.851, Loss_Val: 242.323, Accuracy_Val: 0.710\n",
      "Epoch 1335/10000, Loss: 622.148, Accuracy: 0.857, Loss_Val: 234.280, Accuracy_Val: 0.720\n",
      "Epoch 1350/10000, Loss: 621.774, Accuracy: 0.850, Loss_Val: 218.779, Accuracy_Val: 0.713\n",
      "Epoch 1365/10000, Loss: 617.490, Accuracy: 0.862, Loss_Val: 220.046, Accuracy_Val: 0.708\n",
      "Epoch 1380/10000, Loss: 597.696, Accuracy: 0.861, Loss_Val: 244.600, Accuracy_Val: 0.691\n",
      "Epoch 1395/10000, Loss: 595.831, Accuracy: 0.866, Loss_Val: 236.273, Accuracy_Val: 0.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1410/10000, Loss: 578.599, Accuracy: 0.864, Loss_Val: 234.405, Accuracy_Val: 0.713\n",
      "Epoch 1425/10000, Loss: 578.258, Accuracy: 0.863, Loss_Val: 230.890, Accuracy_Val: 0.710\n",
      "Epoch 1440/10000, Loss: 557.965, Accuracy: 0.873, Loss_Val: 243.078, Accuracy_Val: 0.700\n",
      "Epoch 1455/10000, Loss: 560.181, Accuracy: 0.878, Loss_Val: 239.716, Accuracy_Val: 0.684\n",
      "Epoch 1470/10000, Loss: 553.397, Accuracy: 0.877, Loss_Val: 235.885, Accuracy_Val: 0.708\n",
      "Epoch 1485/10000, Loss: 564.016, Accuracy: 0.878, Loss_Val: 217.000, Accuracy_Val: 0.758\n",
      "Epoch 1500/10000, Loss: 583.205, Accuracy: 0.867, Loss_Val: 232.203, Accuracy_Val: 0.722\n",
      "Epoch 1515/10000, Loss: 557.711, Accuracy: 0.878, Loss_Val: 232.903, Accuracy_Val: 0.710\n",
      "Epoch 1530/10000, Loss: 549.765, Accuracy: 0.877, Loss_Val: 231.808, Accuracy_Val: 0.713\n",
      "Epoch 1545/10000, Loss: 527.961, Accuracy: 0.882, Loss_Val: 205.695, Accuracy_Val: 0.727\n",
      "Epoch 1560/10000, Loss: 531.664, Accuracy: 0.869, Loss_Val: 244.161, Accuracy_Val: 0.715\n",
      "Epoch 1575/10000, Loss: 566.242, Accuracy: 0.861, Loss_Val: 253.176, Accuracy_Val: 0.700\n",
      "Epoch 1590/10000, Loss: 551.323, Accuracy: 0.880, Loss_Val: 227.591, Accuracy_Val: 0.720\n",
      "Epoch 1605/10000, Loss: 497.225, Accuracy: 0.883, Loss_Val: 237.717, Accuracy_Val: 0.727\n",
      "Epoch 1620/10000, Loss: 544.978, Accuracy: 0.878, Loss_Val: 232.692, Accuracy_Val: 0.734\n",
      "Epoch 1635/10000, Loss: 513.025, Accuracy: 0.878, Loss_Val: 232.576, Accuracy_Val: 0.693\n",
      "Epoch 1650/10000, Loss: 484.920, Accuracy: 0.895, Loss_Val: 243.533, Accuracy_Val: 0.710\n",
      "Epoch 1665/10000, Loss: 491.410, Accuracy: 0.881, Loss_Val: 239.707, Accuracy_Val: 0.703\n",
      "Epoch 1680/10000, Loss: 493.493, Accuracy: 0.888, Loss_Val: 234.253, Accuracy_Val: 0.732\n",
      "Epoch 1695/10000, Loss: 500.650, Accuracy: 0.893, Loss_Val: 215.940, Accuracy_Val: 0.756\n",
      "Epoch 1710/10000, Loss: 513.190, Accuracy: 0.887, Loss_Val: 229.287, Accuracy_Val: 0.725\n",
      "Epoch 1725/10000, Loss: 482.161, Accuracy: 0.895, Loss_Val: 227.352, Accuracy_Val: 0.720\n",
      "Epoch 1740/10000, Loss: 446.291, Accuracy: 0.902, Loss_Val: 235.508, Accuracy_Val: 0.732\n",
      "Epoch 1755/10000, Loss: 459.981, Accuracy: 0.898, Loss_Val: 231.158, Accuracy_Val: 0.734\n",
      "Epoch 1770/10000, Loss: 438.819, Accuracy: 0.900, Loss_Val: 226.922, Accuracy_Val: 0.746\n",
      "Epoch 1785/10000, Loss: 458.913, Accuracy: 0.901, Loss_Val: 232.020, Accuracy_Val: 0.729\n",
      "Epoch 1800/10000, Loss: 453.285, Accuracy: 0.901, Loss_Val: 214.910, Accuracy_Val: 0.778\n",
      "Epoch 1815/10000, Loss: 445.938, Accuracy: 0.901, Loss_Val: 237.348, Accuracy_Val: 0.744\n",
      "Epoch 1830/10000, Loss: 461.682, Accuracy: 0.898, Loss_Val: 231.232, Accuracy_Val: 0.744\n",
      "Epoch 1845/10000, Loss: 416.920, Accuracy: 0.918, Loss_Val: 240.935, Accuracy_Val: 0.727\n",
      "Epoch 1860/10000, Loss: 424.870, Accuracy: 0.902, Loss_Val: 234.131, Accuracy_Val: 0.771\n",
      "Epoch 1875/10000, Loss: 455.987, Accuracy: 0.900, Loss_Val: 234.073, Accuracy_Val: 0.751\n",
      "Epoch 1890/10000, Loss: 434.223, Accuracy: 0.905, Loss_Val: 256.705, Accuracy_Val: 0.725\n",
      "Epoch 1905/10000, Loss: 423.287, Accuracy: 0.908, Loss_Val: 232.560, Accuracy_Val: 0.758\n",
      "Epoch 1920/10000, Loss: 435.136, Accuracy: 0.905, Loss_Val: 228.753, Accuracy_Val: 0.739\n",
      "Epoch 1935/10000, Loss: 423.282, Accuracy: 0.912, Loss_Val: 230.976, Accuracy_Val: 0.761\n",
      "Epoch 1950/10000, Loss: 396.395, Accuracy: 0.917, Loss_Val: 241.784, Accuracy_Val: 0.744\n",
      "Epoch 1965/10000, Loss: 415.560, Accuracy: 0.908, Loss_Val: 235.199, Accuracy_Val: 0.763\n",
      "Epoch 1980/10000, Loss: 404.711, Accuracy: 0.913, Loss_Val: 235.486, Accuracy_Val: 0.742\n",
      "Epoch 1995/10000, Loss: 394.616, Accuracy: 0.915, Loss_Val: 241.918, Accuracy_Val: 0.742\n",
      "Epoch 2010/10000, Loss: 390.061, Accuracy: 0.919, Loss_Val: 239.481, Accuracy_Val: 0.749\n",
      "Epoch 2025/10000, Loss: 381.382, Accuracy: 0.920, Loss_Val: 253.811, Accuracy_Val: 0.742\n",
      "Epoch 2040/10000, Loss: 384.047, Accuracy: 0.918, Loss_Val: 242.404, Accuracy_Val: 0.766\n",
      "Epoch 2055/10000, Loss: 373.167, Accuracy: 0.917, Loss_Val: 228.555, Accuracy_Val: 0.737\n",
      "Epoch 2070/10000, Loss: 359.279, Accuracy: 0.924, Loss_Val: 239.156, Accuracy_Val: 0.746\n",
      "Epoch 2085/10000, Loss: 342.591, Accuracy: 0.925, Loss_Val: 230.836, Accuracy_Val: 0.766\n",
      "Epoch 2100/10000, Loss: 340.794, Accuracy: 0.931, Loss_Val: 247.044, Accuracy_Val: 0.758\n",
      "Epoch 2115/10000, Loss: 345.062, Accuracy: 0.925, Loss_Val: 243.042, Accuracy_Val: 0.749\n",
      "Epoch 2130/10000, Loss: 359.789, Accuracy: 0.929, Loss_Val: 268.497, Accuracy_Val: 0.742\n",
      "Epoch 2145/10000, Loss: 357.350, Accuracy: 0.921, Loss_Val: 255.399, Accuracy_Val: 0.729\n",
      "Epoch 2160/10000, Loss: 356.129, Accuracy: 0.926, Loss_Val: 254.573, Accuracy_Val: 0.746\n",
      "Epoch 2175/10000, Loss: 321.804, Accuracy: 0.939, Loss_Val: 263.671, Accuracy_Val: 0.763\n",
      "Epoch 2190/10000, Loss: 345.728, Accuracy: 0.931, Loss_Val: 284.842, Accuracy_Val: 0.734\n",
      "Epoch 2205/10000, Loss: 321.711, Accuracy: 0.937, Loss_Val: 255.037, Accuracy_Val: 0.758\n",
      "Epoch 2220/10000, Loss: 306.333, Accuracy: 0.936, Loss_Val: 243.386, Accuracy_Val: 0.749\n",
      "Epoch 2235/10000, Loss: 341.397, Accuracy: 0.929, Loss_Val: 276.111, Accuracy_Val: 0.751\n",
      "Epoch 2250/10000, Loss: 304.285, Accuracy: 0.938, Loss_Val: 263.554, Accuracy_Val: 0.756\n",
      "Epoch 2265/10000, Loss: 320.755, Accuracy: 0.931, Loss_Val: 261.221, Accuracy_Val: 0.749\n",
      "Epoch 2280/10000, Loss: 302.043, Accuracy: 0.944, Loss_Val: 269.617, Accuracy_Val: 0.725\n",
      "Epoch 2295/10000, Loss: 289.626, Accuracy: 0.945, Loss_Val: 251.396, Accuracy_Val: 0.785\n",
      "Epoch 2310/10000, Loss: 298.707, Accuracy: 0.937, Loss_Val: 292.087, Accuracy_Val: 0.756\n",
      "Epoch 2325/10000, Loss: 285.833, Accuracy: 0.946, Loss_Val: 281.380, Accuracy_Val: 0.737\n",
      "Epoch 2340/10000, Loss: 278.309, Accuracy: 0.939, Loss_Val: 269.996, Accuracy_Val: 0.732\n",
      "Epoch 2355/10000, Loss: 293.328, Accuracy: 0.936, Loss_Val: 293.238, Accuracy_Val: 0.737\n",
      "Epoch 2370/10000, Loss: 302.194, Accuracy: 0.937, Loss_Val: 281.773, Accuracy_Val: 0.737\n",
      "Epoch 2385/10000, Loss: 293.584, Accuracy: 0.940, Loss_Val: 275.214, Accuracy_Val: 0.751\n",
      "Epoch 2400/10000, Loss: 310.677, Accuracy: 0.939, Loss_Val: 296.459, Accuracy_Val: 0.754\n",
      "Epoch 2415/10000, Loss: 291.155, Accuracy: 0.940, Loss_Val: 289.076, Accuracy_Val: 0.754\n",
      "Epoch 2430/10000, Loss: 271.408, Accuracy: 0.946, Loss_Val: 290.774, Accuracy_Val: 0.758\n",
      "Epoch 2445/10000, Loss: 289.778, Accuracy: 0.939, Loss_Val: 265.139, Accuracy_Val: 0.758\n",
      "Epoch 2460/10000, Loss: 272.390, Accuracy: 0.948, Loss_Val: 281.591, Accuracy_Val: 0.768\n",
      "Epoch 2475/10000, Loss: 250.874, Accuracy: 0.949, Loss_Val: 281.616, Accuracy_Val: 0.749\n",
      "Epoch 2490/10000, Loss: 265.874, Accuracy: 0.949, Loss_Val: 284.455, Accuracy_Val: 0.766\n",
      "Epoch 2505/10000, Loss: 268.341, Accuracy: 0.952, Loss_Val: 301.642, Accuracy_Val: 0.761\n",
      "Epoch 2520/10000, Loss: 259.893, Accuracy: 0.954, Loss_Val: 279.963, Accuracy_Val: 0.758\n",
      "Epoch 2535/10000, Loss: 264.901, Accuracy: 0.948, Loss_Val: 306.226, Accuracy_Val: 0.758\n",
      "Epoch 2550/10000, Loss: 248.233, Accuracy: 0.953, Loss_Val: 312.517, Accuracy_Val: 0.739\n",
      "Epoch 2565/10000, Loss: 263.233, Accuracy: 0.948, Loss_Val: 285.657, Accuracy_Val: 0.768\n",
      "Epoch 2580/10000, Loss: 247.496, Accuracy: 0.953, Loss_Val: 298.972, Accuracy_Val: 0.763\n",
      "Epoch 2595/10000, Loss: 255.804, Accuracy: 0.947, Loss_Val: 298.377, Accuracy_Val: 0.766\n",
      "Epoch 2610/10000, Loss: 242.414, Accuracy: 0.955, Loss_Val: 283.857, Accuracy_Val: 0.758\n",
      "Epoch 2625/10000, Loss: 262.145, Accuracy: 0.948, Loss_Val: 297.351, Accuracy_Val: 0.756\n",
      "Epoch 2640/10000, Loss: 234.341, Accuracy: 0.957, Loss_Val: 298.822, Accuracy_Val: 0.758\n",
      "Epoch 2655/10000, Loss: 232.908, Accuracy: 0.947, Loss_Val: 307.823, Accuracy_Val: 0.758\n",
      "Epoch 2670/10000, Loss: 218.374, Accuracy: 0.959, Loss_Val: 306.803, Accuracy_Val: 0.742\n",
      "Epoch 2685/10000, Loss: 213.066, Accuracy: 0.964, Loss_Val: 276.658, Accuracy_Val: 0.771\n",
      "Epoch 2700/10000, Loss: 227.220, Accuracy: 0.959, Loss_Val: 322.770, Accuracy_Val: 0.749\n",
      "Epoch 2715/10000, Loss: 219.253, Accuracy: 0.958, Loss_Val: 307.275, Accuracy_Val: 0.734\n",
      "Epoch 2730/10000, Loss: 234.196, Accuracy: 0.958, Loss_Val: 309.766, Accuracy_Val: 0.761\n",
      "Epoch 2745/10000, Loss: 213.043, Accuracy: 0.963, Loss_Val: 302.994, Accuracy_Val: 0.751\n",
      "Epoch 2760/10000, Loss: 214.095, Accuracy: 0.961, Loss_Val: 310.599, Accuracy_Val: 0.720\n",
      "Epoch 2775/10000, Loss: 205.698, Accuracy: 0.962, Loss_Val: 328.341, Accuracy_Val: 0.739\n",
      "Epoch 2790/10000, Loss: 210.406, Accuracy: 0.958, Loss_Val: 308.294, Accuracy_Val: 0.771\n",
      "Epoch 2805/10000, Loss: 223.860, Accuracy: 0.954, Loss_Val: 339.375, Accuracy_Val: 0.744\n",
      "Epoch 2820/10000, Loss: 231.806, Accuracy: 0.953, Loss_Val: 340.206, Accuracy_Val: 0.734\n",
      "Epoch 2835/10000, Loss: 201.322, Accuracy: 0.964, Loss_Val: 328.467, Accuracy_Val: 0.778\n",
      "Epoch 2850/10000, Loss: 194.536, Accuracy: 0.965, Loss_Val: 337.604, Accuracy_Val: 0.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2865/10000, Loss: 206.166, Accuracy: 0.966, Loss_Val: 293.571, Accuracy_Val: 0.773\n",
      "Epoch 2880/10000, Loss: 204.064, Accuracy: 0.964, Loss_Val: 349.338, Accuracy_Val: 0.756\n",
      "Epoch 2895/10000, Loss: 193.989, Accuracy: 0.967, Loss_Val: 356.988, Accuracy_Val: 0.763\n",
      "Epoch 2910/10000, Loss: 210.258, Accuracy: 0.962, Loss_Val: 297.139, Accuracy_Val: 0.775\n",
      "Epoch 2925/10000, Loss: 181.747, Accuracy: 0.970, Loss_Val: 342.099, Accuracy_Val: 0.746\n",
      "Epoch 2940/10000, Loss: 208.225, Accuracy: 0.963, Loss_Val: 323.341, Accuracy_Val: 0.739\n",
      "Epoch 2955/10000, Loss: 194.956, Accuracy: 0.964, Loss_Val: 340.714, Accuracy_Val: 0.766\n",
      "Epoch 2970/10000, Loss: 194.922, Accuracy: 0.961, Loss_Val: 315.936, Accuracy_Val: 0.768\n",
      "Epoch 2985/10000, Loss: 174.768, Accuracy: 0.969, Loss_Val: 340.998, Accuracy_Val: 0.771\n",
      "Epoch 3000/10000, Loss: 181.601, Accuracy: 0.964, Loss_Val: 343.537, Accuracy_Val: 0.766\n",
      "Epoch 3015/10000, Loss: 179.467, Accuracy: 0.967, Loss_Val: 344.505, Accuracy_Val: 0.756\n",
      "Epoch 3030/10000, Loss: 158.994, Accuracy: 0.973, Loss_Val: 368.678, Accuracy_Val: 0.754\n",
      "Epoch 3045/10000, Loss: 184.908, Accuracy: 0.964, Loss_Val: 358.449, Accuracy_Val: 0.744\n",
      "Final Model, Loss_Val: 248.123, Accuracy_Val: 0.766\n",
      "Final Model, Loss_Test: 143.788, Accuracy_Test: 0.845\n"
     ]
    }
   ],
   "source": [
    "# NN MODEL WITH RESULTS\n",
    "\n",
    "hidden_neurons = 32\n",
    "n_outputs = 1\n",
    "num_epochs = 10000\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(n_mfcc, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p = 0.2),\n",
    "    torch.nn.Linear(hidden_neurons, hidden_neurons),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(p = 0.2),\n",
    "    torch.nn.Linear(hidden_neurons, n_outputs),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "criterion = torch.nn.BCELoss(reduction='sum')\n",
    "\n",
    "learning_rate = 5e-5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "minimum = 0\n",
    "best_model = None\n",
    "\n",
    "no_improve = 0\n",
    "early_stopping_steps = 49\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    y_pred = model(data_train_tensor)\n",
    "        \n",
    "    loss = criterion(y_pred, labels_train_tensor)\n",
    "    \n",
    "    if epoch % 15 == 14:\n",
    "        \n",
    "        y_pred_val = model(data_val_tensor)\n",
    "        loss_val = criterion(y_pred_val, labels_val_tensor)\n",
    "        \n",
    "        #Accuracy \n",
    "        output       = (y_pred > 0.5).float()\n",
    "        correct      = (output == labels_train_tensor).float().sum()\n",
    "        output_val   = (y_pred_val > 0.5).float()\n",
    "        correct_val  = (output_val == labels_val_tensor).float().sum()\n",
    "        accuracy_val = correct_val/labels_val_tensor.shape[0]\n",
    "        \n",
    "        if accuracy_val > minimum:\n",
    "            minimum = accuracy_val\n",
    "            torch.save({'state_dict':model.state_dict(), 'optimizer': optimizer.state_dict()}, 'model.pth.tar')          \n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "        \n",
    "        print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}, Loss_Val: {:.3f}, Accuracy_Val: {:.3f}\".format(epoch+1,\n",
    "                        num_epochs, loss, correct/labels_train_tensor.shape[0], loss_val, correct_val/labels_val_tensor.shape[0]))  \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # early stopping\n",
    "    if no_improve > early_stopping_steps:\n",
    "        break\n",
    "\n",
    "checkpoint = torch.load('model.pth.tar')         \n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "model.eval()\n",
    "\n",
    "y_pred_val = model(data_val_tensor)\n",
    "loss_val = criterion(y_pred_val, labels_val_tensor)\n",
    "output_val  = (y_pred_val > 0.5).float()\n",
    "correct_val = (output_val == labels_val_tensor).float().sum()\n",
    "        \n",
    "print(\"Final Model, Loss_Val: {:.3f}, Accuracy_Val: {:.3f}\".format(loss_val, correct_val/labels_val_tensor.shape[0])) \n",
    "\n",
    "y_pred_test = model(data_test_tensor)\n",
    "loss_test = criterion(y_pred_test, labels_test_tensor)\n",
    "output_test  = (y_pred_test > 0.5).float()\n",
    "correct_test = (output_test == labels_test_tensor).float().sum()\n",
    "        \n",
    "print(\"Final Model, Loss_Test: {:.3f}, Accuracy_Test: {:.3f}\".format(loss_test, correct_test/labels_test_tensor.shape[0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5000, Accuracy: 0.879, Accuracy_Val: 0.616\n",
      "Epoch 10/5000, Accuracy: 0.881, Accuracy_Val: 0.659\n",
      "Epoch 15/5000, Accuracy: 0.871, Accuracy_Val: 0.691\n",
      "Epoch 20/5000, Accuracy: 0.860, Accuracy_Val: 0.691\n",
      "Epoch 25/5000, Accuracy: 0.871, Accuracy_Val: 0.717\n",
      "Epoch 30/5000, Accuracy: 0.879, Accuracy_Val: 0.715\n",
      "Epoch 35/5000, Accuracy: 0.894, Accuracy_Val: 0.705\n",
      "Epoch 40/5000, Accuracy: 0.910, Accuracy_Val: 0.703\n",
      "Epoch 45/5000, Accuracy: 0.923, Accuracy_Val: 0.696\n",
      "Epoch 50/5000, Accuracy: 0.912, Accuracy_Val: 0.700\n",
      "Epoch 55/5000, Accuracy: 0.917, Accuracy_Val: 0.698\n",
      "Epoch 60/5000, Accuracy: 0.917, Accuracy_Val: 0.691\n",
      "Epoch 65/5000, Accuracy: 0.918, Accuracy_Val: 0.691\n",
      "Epoch 70/5000, Accuracy: 0.930, Accuracy_Val: 0.691\n",
      "Epoch 75/5000, Accuracy: 0.936, Accuracy_Val: 0.696\n",
      "Epoch 80/5000, Accuracy: 0.926, Accuracy_Val: 0.688\n",
      "Epoch 85/5000, Accuracy: 0.946, Accuracy_Val: 0.688\n",
      "Epoch 90/5000, Accuracy: 0.949, Accuracy_Val: 0.688\n",
      "Epoch 95/5000, Accuracy: 0.926, Accuracy_Val: 0.676\n",
      "Epoch 100/5000, Accuracy: 0.931, Accuracy_Val: 0.664\n",
      "Epoch 105/5000, Accuracy: 0.951, Accuracy_Val: 0.669\n",
      "Epoch 110/5000, Accuracy: 0.951, Accuracy_Val: 0.662\n",
      "Epoch 115/5000, Accuracy: 0.958, Accuracy_Val: 0.659\n",
      "Epoch 120/5000, Accuracy: 0.934, Accuracy_Val: 0.657\n",
      "Epoch 125/5000, Accuracy: 0.963, Accuracy_Val: 0.662\n",
      "Epoch 130/5000, Accuracy: 0.961, Accuracy_Val: 0.652\n",
      "Epoch 135/5000, Accuracy: 0.960, Accuracy_Val: 0.657\n",
      "Epoch 140/5000, Accuracy: 0.960, Accuracy_Val: 0.652\n",
      "Epoch 145/5000, Accuracy: 0.965, Accuracy_Val: 0.650\n",
      "Epoch 150/5000, Accuracy: 0.954, Accuracy_Val: 0.655\n",
      "Epoch 155/5000, Accuracy: 0.935, Accuracy_Val: 0.655\n",
      "Epoch 160/5000, Accuracy: 0.956, Accuracy_Val: 0.650\n",
      "Epoch 165/5000, Accuracy: 0.948, Accuracy_Val: 0.647\n",
      "Epoch 170/5000, Accuracy: 0.949, Accuracy_Val: 0.650\n",
      "Epoch 175/5000, Accuracy: 0.948, Accuracy_Val: 0.655\n",
      "Best Result, Accuracy_Val: 0.717\n",
      "Best Result, Accuracy_Test: 0.810\n"
     ]
    }
   ],
   "source": [
    "# SVM MODEL WITH RESULTS\n",
    "\n",
    "dim = 39\n",
    "w = torch.autograd.Variable(torch.rand(dim), requires_grad=True)\n",
    "b = torch.autograd.Variable(torch.rand(1),   requires_grad=True)\n",
    "\n",
    "step_size = 3e-5\n",
    "num_epochs = 5000\n",
    "minibatch_size = 20\n",
    "\n",
    "w_best = None\n",
    "b_best = None\n",
    "\n",
    "minimum = 0\n",
    "no_improve = 0\n",
    "early_stopping_steps = 29 \n",
    "\n",
    "def accuracy(X, y):\n",
    "    correct = 0\n",
    "    for i in range(len(y)):\n",
    "        y_predicted = int(np.sign((torch.dot(w, X[i]) - b).detach().numpy()[0]))\n",
    "        if y_predicted == y[i]: correct += 1\n",
    "    return float(correct)/len(y)\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    inds = [i for i in range(len(data_train_tensor))]\n",
    "    for i in range(len(inds)):\n",
    "        L = max(0, 1 - labels_train_svm_tensor[inds[i]] * (torch.dot(w, data_train_tensor[inds[i]]) - b))\n",
    "        if L != 0: # if the loss is zero, Pytorch leaves the variables as a float 0.0, so we can't call backward() on it\n",
    "            L.backward()\n",
    "            w.data -= step_size * w.grad.data # step\n",
    "            b.data -= step_size * b.grad.data # step\n",
    "            w.grad.data.zero_()\n",
    "            b.grad.data.zero_()\n",
    "    \n",
    "    if epoch % 5 == 4:\n",
    "        accuracy_val = accuracy(data_val_tensor, labels_val_svm_tensor)\n",
    "        \n",
    "        if accuracy_val > minimum:\n",
    "            minimum = accuracy_val\n",
    "            w_best = copy.deepcopy(w)\n",
    "            b_best = copy.deepcopy(b)\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "\n",
    "        print(\"Epoch {}/{}, Accuracy: {:.3f}, Accuracy_Val: {:.3f}\".format(epoch+1, num_epochs, \n",
    "                        accuracy(data_train_tensor, labels_train_svm_tensor), accuracy(data_val_tensor, labels_val_svm_tensor)))  \n",
    "    \n",
    "    # early stopping\n",
    "    if no_improve > early_stopping_steps:\n",
    "        break\n",
    "\n",
    "w = w_best\n",
    "b = b_best\n",
    "\n",
    "print(\"Best Result, Accuracy_Val: {:.3f}\".format(accuracy(data_val_tensor, labels_val_svm_tensor)))  \n",
    "print(\"Best Result, Accuracy_Test: {:.3f}\".format(accuracy(data_test_tensor, labels_test_svm_tensor)))  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
